{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+ou+92YbvfgbPlkuUp/8p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/202200474/python-/blob/main/202200474_%EA%B9%80%EB%82%98%ED%98%84_%EC%8B%AC%EC%9E%A5%EB%B3%91_%EB%B0%9C%EB%B3%91_%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "pgmGofawEkhO",
        "outputId": "a2059e08-8b73-4c9c-b8d5-e4cbf04579fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2eeaec00-ef02-4be5-8ad6-0b7a2ec4d5bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2eeaec00-ef02-4be5-8ad6-0b7a2ec4d5bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart disease classification dataset.csv to heart disease classification dataset.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "thalach       5\n",
              "trestbps      4\n",
              "chol          1\n",
              "Unnamed: 0    0\n",
              "age           0\n",
              "sex           0\n",
              "cp            0\n",
              "fbs           0\n",
              "restecg       0\n",
              "exang         0\n",
              "oldpeak       0\n",
              "slope         0\n",
              "ca            0\n",
              "thal          0\n",
              "target        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "myfile = files.upload()\n",
        "df = pd.read_csv('heart disease classification dataset.csv')\n",
        "\n",
        "df.isnull().sum().sort_values(ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:,['thalach','trestbps','chol']] = pd.get_dummies(df.loc[:,['thalach','trestbps','chol']])\n",
        "\n",
        "df.loc[:,['thalach','trestbps','chol']] = df.loc[:,['thalach','trestbps','chol']].fillna(df.loc[:,['thalach','trestbps','chol']].mean())\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "MZ3PrjOOEucY",
        "outputId": "4a858560-7cfe-420b-9818-c90d8a86a405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  age     sex  cp    trestbps   chol  fbs  restecg  thalach  \\\n",
              "0             0   63    male   3  145.000000  233.0    1        0    150.0   \n",
              "1             1   37    male   2  130.000000  250.0    0        1    187.0   \n",
              "2             2   41  female   1  130.000000  204.0    0        0    172.0   \n",
              "3             3   56    male   1  120.000000  236.0    0        1    178.0   \n",
              "4             4   57  female   0  131.712375  354.0    0        1    163.0   \n",
              "..          ...  ...     ...  ..         ...    ...  ...      ...      ...   \n",
              "298         298   57  female   0  140.000000  241.0    0        1    123.0   \n",
              "299         299   45    male   3  110.000000  264.0    0        1    132.0   \n",
              "300         300   68    male   0  144.000000  193.0    1        1    141.0   \n",
              "301         301   57    male   0  131.712375  131.0    0        1    115.0   \n",
              "302         302   57  female   1  130.000000  236.0    0        0    174.0   \n",
              "\n",
              "     exang  oldpeak  slope  ca  thal target  \n",
              "0        0      2.3      0   0     1    yes  \n",
              "1        0      3.5      0   0     2    yes  \n",
              "2        0      1.4      2   0     2    yes  \n",
              "3        0      0.8      2   0     2    yes  \n",
              "4        1      0.6      2   0     2    yes  \n",
              "..     ...      ...    ...  ..   ...    ...  \n",
              "298      1      0.2      1   0     3     no  \n",
              "299      0      1.2      1   0     3     no  \n",
              "300      0      3.4      1   2     3     no  \n",
              "301      1      1.2      1   1     3     no  \n",
              "302      0      0.0      1   1     2     no  \n",
              "\n",
              "[303 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ebdd81f-012e-490e-86be-2788810b1a2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>male</td>\n",
              "      <td>3</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>male</td>\n",
              "      <td>2</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>298</td>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>241.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>299</td>\n",
              "      <td>45</td>\n",
              "      <td>male</td>\n",
              "      <td>3</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>300</td>\n",
              "      <td>68</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>193.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>301</td>\n",
              "      <td>57</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>302</td>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ebdd81f-012e-490e-86be-2788810b1a2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ebdd81f-012e-490e-86be-2788810b1a2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ebdd81f-012e-490e-86be-2788810b1a2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:,2] = pd.get_dummies(df.iloc[:,2])\n",
        "df.iloc[:,14] = pd.get_dummies(df.iloc[:,14])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "iyQykKjXEulD",
        "outputId": "4f66d63a-92ee-4323-edc9-c866796fe034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  age  sex  cp    trestbps   chol  fbs  restecg  thalach  \\\n",
              "0             0   63    0   3  145.000000  233.0    1        0    150.0   \n",
              "1             1   37    0   2  130.000000  250.0    0        1    187.0   \n",
              "2             2   41    1   1  130.000000  204.0    0        0    172.0   \n",
              "3             3   56    0   1  120.000000  236.0    0        1    178.0   \n",
              "4             4   57    1   0  131.712375  354.0    0        1    163.0   \n",
              "..          ...  ...  ...  ..         ...    ...  ...      ...      ...   \n",
              "298         298   57    1   0  140.000000  241.0    0        1    123.0   \n",
              "299         299   45    0   3  110.000000  264.0    0        1    132.0   \n",
              "300         300   68    0   0  144.000000  193.0    1        1    141.0   \n",
              "301         301   57    0   0  131.712375  131.0    0        1    115.0   \n",
              "302         302   57    1   1  130.000000  236.0    0        0    174.0   \n",
              "\n",
              "     exang  oldpeak  slope  ca  thal  target  \n",
              "0        0      2.3      0   0     1       0  \n",
              "1        0      3.5      0   0     2       0  \n",
              "2        0      1.4      2   0     2       0  \n",
              "3        0      0.8      2   0     2       0  \n",
              "4        1      0.6      2   0     2       0  \n",
              "..     ...      ...    ...  ..   ...     ...  \n",
              "298      1      0.2      1   0     3       1  \n",
              "299      0      1.2      1   0     3       1  \n",
              "300      0      3.4      1   2     3       1  \n",
              "301      1      1.2      1   1     3       1  \n",
              "302      0      0.0      1   1     2       1  \n",
              "\n",
              "[303 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-926c2d97-c4e1-4625-8ad6-99151bdf1d8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>298</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>241.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>299</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>300</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>193.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>301</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>131.712375</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>302</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-926c2d97-c4e1-4625-8ad6-99151bdf1d8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-926c2d97-c4e1-4625-8ad6-99151bdf1d8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-926c2d97-c4e1-4625-8ad6-99151bdf1d8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_df = (df - df.mean())/df.std()\n",
        "\n",
        "normalization_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "uKnh0h9JEuuv",
        "outputId": "0a43ae8a-e57d-4e65-ff13-eaa71724b7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0       age       sex        cp      trestbps      chol  \\\n",
              "0     -1.723493  0.950624 -0.679881  1.969864  7.587772e-01 -0.256991   \n",
              "1     -1.712079 -1.912150 -0.679881  1.000921 -9.778352e-02  0.071053   \n",
              "2     -1.700665 -1.471723  1.465992  0.031978 -9.778352e-02 -0.816596   \n",
              "3     -1.689251  0.179877 -0.679881  0.031978 -6.688240e-01 -0.199101   \n",
              "4     -1.677837  0.289984  1.465992 -0.936965 -1.622995e-15  2.077912   \n",
              "..          ...       ...       ...       ...           ...       ...   \n",
              "298    1.677837  0.289984  1.465992 -0.936965  4.732569e-01 -0.102618   \n",
              "299    1.689251 -1.031296 -0.679881  1.969864 -1.239864e+00  0.341207   \n",
              "300    1.700665  1.501157 -0.679881 -0.936965  7.016731e-01 -1.028860   \n",
              "301    1.712079  0.289984 -0.679881 -0.936965 -1.622995e-15 -2.225257   \n",
              "302    1.723493  0.289984  1.465992  0.031978 -9.778352e-02 -0.199101   \n",
              "\n",
              "          fbs   restecg   thalach    exang   oldpeak     slope        ca  \\\n",
              "0    2.390484 -1.004171  0.005999 -0.69548  1.085542 -2.270822 -0.713249   \n",
              "1   -0.416945  0.897478  1.659547 -0.69548  2.119067 -2.270822 -0.713249   \n",
              "2   -0.416945 -1.004171  0.989190 -0.69548  0.310399  0.974740 -0.713249   \n",
              "3   -0.416945  0.897478  1.257333 -0.69548 -0.206364  0.974740 -0.713249   \n",
              "4   -0.416945  0.897478  0.586975  1.43311 -0.378618  0.974740 -0.713249   \n",
              "..        ...       ...       ...      ...       ...       ...       ...   \n",
              "298 -0.416945  0.897478 -1.200645  1.43311 -0.723126 -0.648041 -0.713249   \n",
              "299 -0.416945  0.897478 -0.798430 -0.69548  0.138144 -0.648041 -0.713249   \n",
              "300  2.390484  0.897478 -0.396216 -0.69548  2.032940 -0.648041  1.242538   \n",
              "301 -0.416945  0.897478 -1.558169  1.43311  0.138144 -0.648041  0.264644   \n",
              "302 -0.416945 -1.004171  1.078571 -0.69548 -0.895381 -0.648041  0.264644   \n",
              "\n",
              "         thal    target  \n",
              "0   -2.145324 -0.913019  \n",
              "1   -0.512075 -0.913019  \n",
              "2   -0.512075 -0.913019  \n",
              "3   -0.512075 -0.913019  \n",
              "4   -0.512075 -0.913019  \n",
              "..        ...       ...  \n",
              "298  1.121174  1.091653  \n",
              "299  1.121174  1.091653  \n",
              "300  1.121174  1.091653  \n",
              "301  1.121174  1.091653  \n",
              "302 -0.512075  1.091653  \n",
              "\n",
              "[303 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ee3854e-07c3-4d78-aa57-bc7a7586c44a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.723493</td>\n",
              "      <td>0.950624</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>1.969864</td>\n",
              "      <td>7.587772e-01</td>\n",
              "      <td>-0.256991</td>\n",
              "      <td>2.390484</td>\n",
              "      <td>-1.004171</td>\n",
              "      <td>0.005999</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>1.085542</td>\n",
              "      <td>-2.270822</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-2.145324</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.712079</td>\n",
              "      <td>-1.912150</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>1.000921</td>\n",
              "      <td>-9.778352e-02</td>\n",
              "      <td>0.071053</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>1.659547</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>2.119067</td>\n",
              "      <td>-2.270822</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.700665</td>\n",
              "      <td>-1.471723</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>0.031978</td>\n",
              "      <td>-9.778352e-02</td>\n",
              "      <td>-0.816596</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>-1.004171</td>\n",
              "      <td>0.989190</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>0.310399</td>\n",
              "      <td>0.974740</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.689251</td>\n",
              "      <td>0.179877</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>0.031978</td>\n",
              "      <td>-6.688240e-01</td>\n",
              "      <td>-0.199101</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>1.257333</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>-0.206364</td>\n",
              "      <td>0.974740</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.677837</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>-1.622995e-15</td>\n",
              "      <td>2.077912</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>0.586975</td>\n",
              "      <td>1.43311</td>\n",
              "      <td>-0.378618</td>\n",
              "      <td>0.974740</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>-0.913019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1.677837</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>4.732569e-01</td>\n",
              "      <td>-0.102618</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-1.200645</td>\n",
              "      <td>1.43311</td>\n",
              "      <td>-0.723126</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1.689251</td>\n",
              "      <td>-1.031296</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>1.969864</td>\n",
              "      <td>-1.239864e+00</td>\n",
              "      <td>0.341207</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-0.798430</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>0.138144</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>-0.713249</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>1.700665</td>\n",
              "      <td>1.501157</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>7.016731e-01</td>\n",
              "      <td>-1.028860</td>\n",
              "      <td>2.390484</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-0.396216</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>2.032940</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>1.242538</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>1.712079</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>-0.679881</td>\n",
              "      <td>-0.936965</td>\n",
              "      <td>-1.622995e-15</td>\n",
              "      <td>-2.225257</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>0.897478</td>\n",
              "      <td>-1.558169</td>\n",
              "      <td>1.43311</td>\n",
              "      <td>0.138144</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>0.264644</td>\n",
              "      <td>1.121174</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>1.723493</td>\n",
              "      <td>0.289984</td>\n",
              "      <td>1.465992</td>\n",
              "      <td>0.031978</td>\n",
              "      <td>-9.778352e-02</td>\n",
              "      <td>-0.199101</td>\n",
              "      <td>-0.416945</td>\n",
              "      <td>-1.004171</td>\n",
              "      <td>1.078571</td>\n",
              "      <td>-0.69548</td>\n",
              "      <td>-0.895381</td>\n",
              "      <td>-0.648041</td>\n",
              "      <td>0.264644</td>\n",
              "      <td>-0.512075</td>\n",
              "      <td>1.091653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ee3854e-07c3-4d78-aa57-bc7a7586c44a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ee3854e-07c3-4d78-aa57-bc7a7586c44a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ee3854e-07c3-4d78-aa57-bc7a7586c44a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "RANDOM_SEED = 3\n",
        "np.random.seed(RANDOM_SEED)\n",
        "x=normalization_df.iloc[:,1:14]\n",
        "\n",
        "y=df.iloc[:,14]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,random_state=3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20,  input_dim=13, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(30,  activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(20,  activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath=\"./data/model/Ch15-house.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=2000, batch_size=30, validation_split=0.2, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "loss = model.evaluate(x_train,y_train)\n",
        "print('accuracy:',loss)\n",
        "\n",
        "y_loss = history.history['loss']\n",
        "y_accu = history.history['accuracy']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len,y_loss)\n",
        "plt.plot(x_len,y_accu, marker='.', c=\"red\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2034
        },
        "id": "5QWJ0OggEu3M",
        "outputId": "364266cd-16ca-4f8c-f681-eeaaea296566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                280       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                630       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,551\n",
            "Trainable params: 1,551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 0.2974 - accuracy: 0.5714 - val_loss: 0.2730 - val_accuracy: 0.4727\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2567 - accuracy: 0.5899 - val_loss: 0.2587 - val_accuracy: 0.5273\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2235 - accuracy: 0.6452 - val_loss: 0.2482 - val_accuracy: 0.4909\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2130 - accuracy: 0.6866 - val_loss: 0.2407 - val_accuracy: 0.5636\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2094 - accuracy: 0.6959 - val_loss: 0.2355 - val_accuracy: 0.5636\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1936 - accuracy: 0.7051 - val_loss: 0.2317 - val_accuracy: 0.5636\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1785 - accuracy: 0.7419 - val_loss: 0.2306 - val_accuracy: 0.6000\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1831 - accuracy: 0.7558 - val_loss: 0.2272 - val_accuracy: 0.6000\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 0.7834 - val_loss: 0.2277 - val_accuracy: 0.6545\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.7788 - val_loss: 0.2228 - val_accuracy: 0.6364\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.7696 - val_loss: 0.2198 - val_accuracy: 0.6545\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 0.7880 - val_loss: 0.2196 - val_accuracy: 0.6909\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1371 - accuracy: 0.8341 - val_loss: 0.2244 - val_accuracy: 0.6909\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.7834 - val_loss: 0.2255 - val_accuracy: 0.6909\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1418 - accuracy: 0.8018 - val_loss: 0.2193 - val_accuracy: 0.6909\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1486 - accuracy: 0.7972 - val_loss: 0.2187 - val_accuracy: 0.6727\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1305 - accuracy: 0.8249 - val_loss: 0.2181 - val_accuracy: 0.6909\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.7926 - val_loss: 0.2226 - val_accuracy: 0.6909\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1433 - accuracy: 0.8018 - val_loss: 0.2268 - val_accuracy: 0.6909\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1286 - accuracy: 0.8157 - val_loss: 0.2262 - val_accuracy: 0.7091\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.8341 - val_loss: 0.2251 - val_accuracy: 0.7091\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.8387 - val_loss: 0.2279 - val_accuracy: 0.7091\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.8525 - val_loss: 0.2292 - val_accuracy: 0.7091\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.8157 - val_loss: 0.2266 - val_accuracy: 0.6727\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.8341 - val_loss: 0.2267 - val_accuracy: 0.6727\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.8525 - val_loss: 0.2319 - val_accuracy: 0.6727\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.8664 - val_loss: 0.2329 - val_accuracy: 0.6727\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.8618 - val_loss: 0.2272 - val_accuracy: 0.6727\n",
            "Epoch 29/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.8525 - val_loss: 0.2256 - val_accuracy: 0.6727\n",
            "Epoch 30/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.8571 - val_loss: 0.2296 - val_accuracy: 0.6545\n",
            "Epoch 31/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.8802 - val_loss: 0.2320 - val_accuracy: 0.6545\n",
            "Epoch 32/2000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.8802 - val_loss: 0.2317 - val_accuracy: 0.6545\n",
            "Epoch 33/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.8848 - val_loss: 0.2321 - val_accuracy: 0.6545\n",
            "Epoch 34/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9078 - val_loss: 0.2298 - val_accuracy: 0.6545\n",
            "Epoch 35/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.8664 - val_loss: 0.2321 - val_accuracy: 0.6545\n",
            "Epoch 36/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.8940 - val_loss: 0.2332 - val_accuracy: 0.6545\n",
            "Epoch 37/2000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9078 - val_loss: 0.2346 - val_accuracy: 0.6545\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.8676\n",
            "accuracy: [0.10505477339029312, 0.8676470518112183]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_test, y_test, epochs= 100, batch_size=30)\n",
        "loss = model.evaluate(x_test,y_test)\n",
        "print('accuracy:',loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX3u6OsPEu_O",
        "outputId": "7b6d4c68-8559-4caa-fff9-6fe2eb3ff028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1850 - accuracy: 0.8065\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.7742\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1425 - accuracy: 0.8710\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1330 - accuracy: 0.8387\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1819 - accuracy: 0.7742\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.7742\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1440 - accuracy: 0.8710\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1037 - accuracy: 0.8710\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.8387\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.8387\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.8710\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.8387\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9032\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1352 - accuracy: 0.8387\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.8387\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.8387\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9032\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9032\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9032\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0943 - accuracy: 0.8387\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9032\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0823 - accuracy: 0.9032\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.8710\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9032\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9677\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 0.9355\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9355\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9677\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.8710\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.8710\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9677\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9032\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9677\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9677\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9677\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9677\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9032\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9677\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9677\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9677\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9677\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9355\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9677\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9677\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9355\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9677\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9355\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9355\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9677\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9677\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9355\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9677\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9677\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9677\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9677\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9355\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9355\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9677\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9677\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0651 - accuracy: 0.9355\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9677\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9355\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9355\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9355\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9677\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9355\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9355\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9677\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9677\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.8710\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9677\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9677\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9355\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9677\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9355\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "accuracy: [0.014720900915563107, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_fold=6\n",
        "skf=KFold(n_splits=n_fold, shuffle=True, random_state=3)\n",
        "\n",
        "for train, test in skf.split(x,y) :\n",
        "  x=normalization_df.iloc[:,1:14]\n",
        "\n",
        "  y=df.iloc[:,14]\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,random_state=3)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10,  input_dim=13, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(30,  activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(40,  activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.summary()\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(x_train, y_train, epochs=200, batch_size=30, validation_split=0.2)\n",
        "  loss = model.evaluate(x_train,y_train)\n",
        "  print('accuracy:',loss)\n",
        "\n",
        "  y_loss = history.history['loss']\n",
        "  y_accu = history.history['accuracy']\n",
        "\n",
        "  x_len = np.arange(len(y_loss))\n",
        "\n",
        "  plt.plot(x_len,y_loss)\n",
        "  plt.plot(x_len,y_accu, marker='.', c=\"red\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47796
        },
        "id": "RWbIlG99EvGE",
        "outputId": "97b6a99d-1673-4566-d808-7b1f7dbe228e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 22ms/step - loss: 0.4038 - accuracy: 0.5392 - val_loss: 0.3348 - val_accuracy: 0.5273\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.5714 - val_loss: 0.2919 - val_accuracy: 0.4909\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.6221 - val_loss: 0.2896 - val_accuracy: 0.5091\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.6959 - val_loss: 0.2678 - val_accuracy: 0.5636\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.7051 - val_loss: 0.2493 - val_accuracy: 0.5455\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.7051 - val_loss: 0.2321 - val_accuracy: 0.6182\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.7327 - val_loss: 0.2236 - val_accuracy: 0.6364\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.7373 - val_loss: 0.2208 - val_accuracy: 0.6364\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.7419 - val_loss: 0.2184 - val_accuracy: 0.6182\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.7419 - val_loss: 0.2091 - val_accuracy: 0.6545\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.7696 - val_loss: 0.2024 - val_accuracy: 0.6909\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.7696 - val_loss: 0.2021 - val_accuracy: 0.6909\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.7834 - val_loss: 0.2022 - val_accuracy: 0.6727\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.7696 - val_loss: 0.1999 - val_accuracy: 0.6727\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.7788 - val_loss: 0.1955 - val_accuracy: 0.7091\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1576 - accuracy: 0.7880 - val_loss: 0.1862 - val_accuracy: 0.7091\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1523 - accuracy: 0.7788 - val_loss: 0.1876 - val_accuracy: 0.7091\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.8203 - val_loss: 0.1910 - val_accuracy: 0.6909\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.8018 - val_loss: 0.1959 - val_accuracy: 0.7091\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.7742 - val_loss: 0.1907 - val_accuracy: 0.7273\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.8479 - val_loss: 0.1914 - val_accuracy: 0.7091\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.8157 - val_loss: 0.1903 - val_accuracy: 0.7091\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.7926 - val_loss: 0.1930 - val_accuracy: 0.7091\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.7926 - val_loss: 0.1884 - val_accuracy: 0.7273\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.8065 - val_loss: 0.1918 - val_accuracy: 0.7091\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.8341 - val_loss: 0.1921 - val_accuracy: 0.7091\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.8157 - val_loss: 0.1919 - val_accuracy: 0.6909\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.8018 - val_loss: 0.1995 - val_accuracy: 0.6727\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.8295 - val_loss: 0.1943 - val_accuracy: 0.7091\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.8065 - val_loss: 0.1958 - val_accuracy: 0.7091\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.8249 - val_loss: 0.1913 - val_accuracy: 0.7091\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1135 - accuracy: 0.8479 - val_loss: 0.1905 - val_accuracy: 0.7091\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.8249 - val_loss: 0.1941 - val_accuracy: 0.6727\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1095 - accuracy: 0.8710 - val_loss: 0.1981 - val_accuracy: 0.6545\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.8571 - val_loss: 0.1938 - val_accuracy: 0.7091\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1141 - accuracy: 0.8479 - val_loss: 0.1941 - val_accuracy: 0.7091\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.8571 - val_loss: 0.1945 - val_accuracy: 0.6909\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1221 - accuracy: 0.8525 - val_loss: 0.1982 - val_accuracy: 0.6909\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.8387 - val_loss: 0.1968 - val_accuracy: 0.6909\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.8664 - val_loss: 0.1935 - val_accuracy: 0.6909\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.8618 - val_loss: 0.1931 - val_accuracy: 0.7091\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.8940 - val_loss: 0.1930 - val_accuracy: 0.7091\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.8618 - val_loss: 0.1906 - val_accuracy: 0.7273\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.8618 - val_loss: 0.1932 - val_accuracy: 0.7091\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.8986 - val_loss: 0.1955 - val_accuracy: 0.7091\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0989 - accuracy: 0.8894 - val_loss: 0.2006 - val_accuracy: 0.6727\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.8433 - val_loss: 0.1942 - val_accuracy: 0.7455\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.8710 - val_loss: 0.1936 - val_accuracy: 0.6909\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0957 - accuracy: 0.8802 - val_loss: 0.1920 - val_accuracy: 0.7091\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.8525 - val_loss: 0.1962 - val_accuracy: 0.7091\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.8571 - val_loss: 0.1985 - val_accuracy: 0.6909\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.8894 - val_loss: 0.1942 - val_accuracy: 0.7091\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1081 - accuracy: 0.8756 - val_loss: 0.2007 - val_accuracy: 0.6909\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 0.8571 - val_loss: 0.2014 - val_accuracy: 0.6909\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.8802 - val_loss: 0.1933 - val_accuracy: 0.7091\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9032 - val_loss: 0.1930 - val_accuracy: 0.6909\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0893 - accuracy: 0.8940 - val_loss: 0.1915 - val_accuracy: 0.6909\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1015 - accuracy: 0.8802 - val_loss: 0.1905 - val_accuracy: 0.6909\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9078 - val_loss: 0.1869 - val_accuracy: 0.7091\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.8710 - val_loss: 0.1914 - val_accuracy: 0.7091\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.8802 - val_loss: 0.1957 - val_accuracy: 0.6909\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.8894 - val_loss: 0.2018 - val_accuracy: 0.6727\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.8940 - val_loss: 0.1977 - val_accuracy: 0.7091\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.8710 - val_loss: 0.2020 - val_accuracy: 0.6545\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.8940 - val_loss: 0.2047 - val_accuracy: 0.6727\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9032 - val_loss: 0.1938 - val_accuracy: 0.6727\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.8894 - val_loss: 0.1924 - val_accuracy: 0.6727\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.8940 - val_loss: 0.2002 - val_accuracy: 0.6727\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.8710 - val_loss: 0.1995 - val_accuracy: 0.6727\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.8940 - val_loss: 0.1980 - val_accuracy: 0.6727\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.8710 - val_loss: 0.2035 - val_accuracy: 0.6909\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.8986 - val_loss: 0.2050 - val_accuracy: 0.6909\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.8940 - val_loss: 0.2038 - val_accuracy: 0.6909\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.8710 - val_loss: 0.2063 - val_accuracy: 0.6909\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9171 - val_loss: 0.2047 - val_accuracy: 0.6909\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.8710 - val_loss: 0.2031 - val_accuracy: 0.6909\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.8986 - val_loss: 0.2095 - val_accuracy: 0.6909\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9171 - val_loss: 0.2060 - val_accuracy: 0.6909\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9171 - val_loss: 0.2049 - val_accuracy: 0.6909\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9032 - val_loss: 0.2076 - val_accuracy: 0.6909\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9032 - val_loss: 0.2055 - val_accuracy: 0.6909\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.8848 - val_loss: 0.2109 - val_accuracy: 0.6909\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.8986 - val_loss: 0.2108 - val_accuracy: 0.6909\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.8710 - val_loss: 0.2025 - val_accuracy: 0.6909\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.8986 - val_loss: 0.2050 - val_accuracy: 0.6909\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.8802 - val_loss: 0.2205 - val_accuracy: 0.6909\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9078 - val_loss: 0.2091 - val_accuracy: 0.6909\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9217 - val_loss: 0.2012 - val_accuracy: 0.6909\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9263 - val_loss: 0.2025 - val_accuracy: 0.6909\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9032 - val_loss: 0.2038 - val_accuracy: 0.6909\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9171 - val_loss: 0.2032 - val_accuracy: 0.6909\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.8940 - val_loss: 0.2131 - val_accuracy: 0.6909\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.8940 - val_loss: 0.2114 - val_accuracy: 0.6909\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9078 - val_loss: 0.2122 - val_accuracy: 0.6909\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9078 - val_loss: 0.2150 - val_accuracy: 0.6909\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0746 - accuracy: 0.9078 - val_loss: 0.2047 - val_accuracy: 0.7091\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9217 - val_loss: 0.2084 - val_accuracy: 0.6909\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9171 - val_loss: 0.2131 - val_accuracy: 0.6909\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9124 - val_loss: 0.2039 - val_accuracy: 0.7273\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.8986 - val_loss: 0.2026 - val_accuracy: 0.7273\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.8986 - val_loss: 0.2001 - val_accuracy: 0.7091\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9217 - val_loss: 0.2059 - val_accuracy: 0.7091\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9171 - val_loss: 0.2155 - val_accuracy: 0.6909\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9171 - val_loss: 0.2195 - val_accuracy: 0.6909\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9078 - val_loss: 0.2103 - val_accuracy: 0.6909\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9078 - val_loss: 0.2024 - val_accuracy: 0.6909\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.8664 - val_loss: 0.1967 - val_accuracy: 0.6909\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 0.9124 - val_loss: 0.1993 - val_accuracy: 0.6909\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9217 - val_loss: 0.2000 - val_accuracy: 0.6909\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9078 - val_loss: 0.1968 - val_accuracy: 0.7273\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9032 - val_loss: 0.2041 - val_accuracy: 0.7091\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9355 - val_loss: 0.2108 - val_accuracy: 0.6909\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.8986 - val_loss: 0.2142 - val_accuracy: 0.6727\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9217 - val_loss: 0.2094 - val_accuracy: 0.7091\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9493 - val_loss: 0.2112 - val_accuracy: 0.7091\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9217 - val_loss: 0.2127 - val_accuracy: 0.7091\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9171 - val_loss: 0.2081 - val_accuracy: 0.7273\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9309 - val_loss: 0.2129 - val_accuracy: 0.7273\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9309 - val_loss: 0.2172 - val_accuracy: 0.7273\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9124 - val_loss: 0.2147 - val_accuracy: 0.7273\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.8894 - val_loss: 0.2127 - val_accuracy: 0.7273\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9447 - val_loss: 0.2037 - val_accuracy: 0.7273\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9263 - val_loss: 0.2070 - val_accuracy: 0.7273\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9217 - val_loss: 0.2143 - val_accuracy: 0.7273\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9309 - val_loss: 0.2186 - val_accuracy: 0.7273\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9171 - val_loss: 0.2131 - val_accuracy: 0.7273\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9171 - val_loss: 0.2193 - val_accuracy: 0.7273\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9309 - val_loss: 0.2165 - val_accuracy: 0.7273\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9217 - val_loss: 0.2086 - val_accuracy: 0.7273\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9217 - val_loss: 0.2185 - val_accuracy: 0.7273\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9309 - val_loss: 0.2102 - val_accuracy: 0.7273\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9401 - val_loss: 0.2067 - val_accuracy: 0.7273\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9447 - val_loss: 0.2116 - val_accuracy: 0.7273\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9493 - val_loss: 0.2164 - val_accuracy: 0.7273\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0571 - accuracy: 0.9493 - val_loss: 0.2264 - val_accuracy: 0.7273\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 0.9078 - val_loss: 0.2222 - val_accuracy: 0.7273\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0598 - accuracy: 0.9355 - val_loss: 0.2146 - val_accuracy: 0.7273\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0584 - accuracy: 0.9171 - val_loss: 0.2158 - val_accuracy: 0.7273\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0591 - accuracy: 0.9309 - val_loss: 0.2260 - val_accuracy: 0.7273\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9263 - val_loss: 0.2207 - val_accuracy: 0.7273\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9263 - val_loss: 0.2178 - val_accuracy: 0.7273\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9124 - val_loss: 0.2160 - val_accuracy: 0.7273\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9493 - val_loss: 0.2194 - val_accuracy: 0.7273\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.9401 - val_loss: 0.2225 - val_accuracy: 0.7273\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9171 - val_loss: 0.2168 - val_accuracy: 0.7273\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9263 - val_loss: 0.2211 - val_accuracy: 0.7273\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9263 - val_loss: 0.2229 - val_accuracy: 0.7273\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9217 - val_loss: 0.2212 - val_accuracy: 0.7273\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9355 - val_loss: 0.2214 - val_accuracy: 0.7273\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0630 - accuracy: 0.9263 - val_loss: 0.2217 - val_accuracy: 0.7273\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0576 - accuracy: 0.9447 - val_loss: 0.2273 - val_accuracy: 0.7273\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0543 - accuracy: 0.9493 - val_loss: 0.2140 - val_accuracy: 0.7273\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0534 - accuracy: 0.9447 - val_loss: 0.2199 - val_accuracy: 0.7273\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0559 - accuracy: 0.9447 - val_loss: 0.2180 - val_accuracy: 0.7273\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 0.9355 - val_loss: 0.2210 - val_accuracy: 0.7273\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9355 - val_loss: 0.2287 - val_accuracy: 0.7273\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9447 - val_loss: 0.2246 - val_accuracy: 0.7273\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9447 - val_loss: 0.2260 - val_accuracy: 0.7273\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9309 - val_loss: 0.2169 - val_accuracy: 0.7273\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9263 - val_loss: 0.2107 - val_accuracy: 0.7273\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9447 - val_loss: 0.2168 - val_accuracy: 0.7273\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9355 - val_loss: 0.2204 - val_accuracy: 0.7273\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9355 - val_loss: 0.2131 - val_accuracy: 0.7273\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9401 - val_loss: 0.2266 - val_accuracy: 0.7273\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0525 - accuracy: 0.9493 - val_loss: 0.2219 - val_accuracy: 0.7273\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0634 - accuracy: 0.9309 - val_loss: 0.2231 - val_accuracy: 0.7273\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0648 - accuracy: 0.9263 - val_loss: 0.2280 - val_accuracy: 0.7273\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0543 - accuracy: 0.9355 - val_loss: 0.2098 - val_accuracy: 0.7273\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0526 - accuracy: 0.9447 - val_loss: 0.2218 - val_accuracy: 0.7273\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9355 - val_loss: 0.2219 - val_accuracy: 0.7273\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9217 - val_loss: 0.2226 - val_accuracy: 0.7273\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9447 - val_loss: 0.2237 - val_accuracy: 0.7273\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9401 - val_loss: 0.2227 - val_accuracy: 0.7273\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9309 - val_loss: 0.2198 - val_accuracy: 0.7273\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9539 - val_loss: 0.2149 - val_accuracy: 0.7273\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0499 - accuracy: 0.9539 - val_loss: 0.2116 - val_accuracy: 0.7273\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9124 - val_loss: 0.2099 - val_accuracy: 0.7273\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9401 - val_loss: 0.2178 - val_accuracy: 0.7273\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9493 - val_loss: 0.2143 - val_accuracy: 0.7273\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9493 - val_loss: 0.2127 - val_accuracy: 0.7273\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9539 - val_loss: 0.2036 - val_accuracy: 0.7455\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9585 - val_loss: 0.2061 - val_accuracy: 0.7455\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9447 - val_loss: 0.2139 - val_accuracy: 0.7273\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9355 - val_loss: 0.2130 - val_accuracy: 0.7273\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9401 - val_loss: 0.2169 - val_accuracy: 0.7273\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9401 - val_loss: 0.2284 - val_accuracy: 0.7273\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9493 - val_loss: 0.2245 - val_accuracy: 0.7273\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9585 - val_loss: 0.2285 - val_accuracy: 0.7273\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9447 - val_loss: 0.2214 - val_accuracy: 0.7455\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9401 - val_loss: 0.2185 - val_accuracy: 0.7455\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9447 - val_loss: 0.2234 - val_accuracy: 0.7455\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9493 - val_loss: 0.2208 - val_accuracy: 0.7455\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9493 - val_loss: 0.2115 - val_accuracy: 0.7455\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9585 - val_loss: 0.2190 - val_accuracy: 0.7455\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9585 - val_loss: 0.2136 - val_accuracy: 0.7455\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9539 - val_loss: 0.2163 - val_accuracy: 0.7455\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9539 - val_loss: 0.2254 - val_accuracy: 0.7455\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9585 - val_loss: 0.2176 - val_accuracy: 0.7455\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9447 - val_loss: 0.2354 - val_accuracy: 0.7273\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0504 - accuracy: 0.9539 - val_loss: 0.2309 - val_accuracy: 0.7273\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9191\n",
            "accuracy: [0.07228553295135498, 0.9191176295280457]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 22ms/step - loss: 0.3861 - accuracy: 0.5392 - val_loss: 0.3731 - val_accuracy: 0.4182\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.5069 - val_loss: 0.3792 - val_accuracy: 0.3636\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2943 - accuracy: 0.5346 - val_loss: 0.3600 - val_accuracy: 0.4182\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.5484 - val_loss: 0.3274 - val_accuracy: 0.4182\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2583 - accuracy: 0.5899 - val_loss: 0.3135 - val_accuracy: 0.4364\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.6452 - val_loss: 0.3080 - val_accuracy: 0.4727\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2240 - accuracy: 0.6544 - val_loss: 0.2946 - val_accuracy: 0.4727\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.6452 - val_loss: 0.2814 - val_accuracy: 0.4909\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1909 - accuracy: 0.6959 - val_loss: 0.2690 - val_accuracy: 0.5455\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.7281 - val_loss: 0.2586 - val_accuracy: 0.5455\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1813 - accuracy: 0.7419 - val_loss: 0.2542 - val_accuracy: 0.5273\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.7419 - val_loss: 0.2423 - val_accuracy: 0.5455\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1730 - accuracy: 0.7465 - val_loss: 0.2341 - val_accuracy: 0.6000\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.7281 - val_loss: 0.2382 - val_accuracy: 0.6000\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.7880 - val_loss: 0.2321 - val_accuracy: 0.6000\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.7834 - val_loss: 0.2260 - val_accuracy: 0.6000\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.7558 - val_loss: 0.2206 - val_accuracy: 0.5818\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1389 - accuracy: 0.7788 - val_loss: 0.2233 - val_accuracy: 0.6182\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.7926 - val_loss: 0.2136 - val_accuracy: 0.6182\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.8157 - val_loss: 0.2089 - val_accuracy: 0.6000\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.8249 - val_loss: 0.2121 - val_accuracy: 0.6364\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.8249 - val_loss: 0.2165 - val_accuracy: 0.6364\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.8618 - val_loss: 0.2140 - val_accuracy: 0.6364\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1443 - accuracy: 0.7926 - val_loss: 0.2034 - val_accuracy: 0.6000\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.7880 - val_loss: 0.2064 - val_accuracy: 0.6545\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1290 - accuracy: 0.8387 - val_loss: 0.2081 - val_accuracy: 0.6545\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.8710 - val_loss: 0.2018 - val_accuracy: 0.6182\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.8065 - val_loss: 0.1968 - val_accuracy: 0.6182\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.8341 - val_loss: 0.2074 - val_accuracy: 0.6364\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.8848 - val_loss: 0.2115 - val_accuracy: 0.6364\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.8618 - val_loss: 0.2042 - val_accuracy: 0.6364\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.8203 - val_loss: 0.2013 - val_accuracy: 0.6364\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.8479 - val_loss: 0.2123 - val_accuracy: 0.6727\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1161 - accuracy: 0.8571 - val_loss: 0.2003 - val_accuracy: 0.6909\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1235 - accuracy: 0.8341 - val_loss: 0.1966 - val_accuracy: 0.6909\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.8525 - val_loss: 0.1969 - val_accuracy: 0.6909\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.8387 - val_loss: 0.1950 - val_accuracy: 0.7091\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.8618 - val_loss: 0.1937 - val_accuracy: 0.7091\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.8710 - val_loss: 0.1916 - val_accuracy: 0.7091\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.8756 - val_loss: 0.1999 - val_accuracy: 0.6909\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.8387 - val_loss: 0.2017 - val_accuracy: 0.6909\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.8756 - val_loss: 0.1968 - val_accuracy: 0.6909\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.8848 - val_loss: 0.1945 - val_accuracy: 0.6909\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.8894 - val_loss: 0.1966 - val_accuracy: 0.6727\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.8756 - val_loss: 0.2043 - val_accuracy: 0.6909\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.8618 - val_loss: 0.2046 - val_accuracy: 0.6909\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0999 - accuracy: 0.8710 - val_loss: 0.1878 - val_accuracy: 0.6909\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1192 - accuracy: 0.8295 - val_loss: 0.1934 - val_accuracy: 0.6909\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.8756 - val_loss: 0.2030 - val_accuracy: 0.6909\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.8664 - val_loss: 0.1972 - val_accuracy: 0.6909\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0964 - accuracy: 0.8802 - val_loss: 0.1957 - val_accuracy: 0.6909\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.8894 - val_loss: 0.1948 - val_accuracy: 0.6909\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.8986 - val_loss: 0.2002 - val_accuracy: 0.6727\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1080 - accuracy: 0.8756 - val_loss: 0.1902 - val_accuracy: 0.6909\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.8848 - val_loss: 0.1875 - val_accuracy: 0.6909\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.8802 - val_loss: 0.1856 - val_accuracy: 0.6909\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.8848 - val_loss: 0.1857 - val_accuracy: 0.6909\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.8525 - val_loss: 0.1918 - val_accuracy: 0.6909\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9078 - val_loss: 0.1882 - val_accuracy: 0.6909\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.8848 - val_loss: 0.1873 - val_accuracy: 0.6909\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.8940 - val_loss: 0.1903 - val_accuracy: 0.6909\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.8986 - val_loss: 0.1974 - val_accuracy: 0.6909\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.8848 - val_loss: 0.1913 - val_accuracy: 0.6909\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.8940 - val_loss: 0.1848 - val_accuracy: 0.6909\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.8940 - val_loss: 0.1876 - val_accuracy: 0.6909\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.8894 - val_loss: 0.1894 - val_accuracy: 0.6909\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.8940 - val_loss: 0.1896 - val_accuracy: 0.6727\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.8618 - val_loss: 0.1843 - val_accuracy: 0.6727\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.8940 - val_loss: 0.1845 - val_accuracy: 0.6727\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.8894 - val_loss: 0.1847 - val_accuracy: 0.6909\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.8756 - val_loss: 0.1806 - val_accuracy: 0.7091\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.8894 - val_loss: 0.1840 - val_accuracy: 0.6909\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.8848 - val_loss: 0.1853 - val_accuracy: 0.6909\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9124 - val_loss: 0.1870 - val_accuracy: 0.6909\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.8986 - val_loss: 0.1910 - val_accuracy: 0.6909\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9078 - val_loss: 0.1925 - val_accuracy: 0.6909\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.8894 - val_loss: 0.1857 - val_accuracy: 0.7091\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.8848 - val_loss: 0.1950 - val_accuracy: 0.6727\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9401 - val_loss: 0.1980 - val_accuracy: 0.6909\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9217 - val_loss: 0.1886 - val_accuracy: 0.7091\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.8940 - val_loss: 0.1844 - val_accuracy: 0.6909\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.8802 - val_loss: 0.1820 - val_accuracy: 0.6909\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9032 - val_loss: 0.1855 - val_accuracy: 0.6727\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.8894 - val_loss: 0.1862 - val_accuracy: 0.6727\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0921 - accuracy: 0.8802 - val_loss: 0.1813 - val_accuracy: 0.6727\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.8986 - val_loss: 0.1814 - val_accuracy: 0.6909\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9171 - val_loss: 0.1855 - val_accuracy: 0.7091\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9217 - val_loss: 0.1937 - val_accuracy: 0.7091\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.8802 - val_loss: 0.1804 - val_accuracy: 0.7091\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9217 - val_loss: 0.1801 - val_accuracy: 0.7273\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9263 - val_loss: 0.1789 - val_accuracy: 0.7091\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9217 - val_loss: 0.1777 - val_accuracy: 0.7091\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9171 - val_loss: 0.1812 - val_accuracy: 0.7091\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9078 - val_loss: 0.1795 - val_accuracy: 0.7273\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9401 - val_loss: 0.1823 - val_accuracy: 0.7455\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.8986 - val_loss: 0.1793 - val_accuracy: 0.7455\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9171 - val_loss: 0.1781 - val_accuracy: 0.7455\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.8940 - val_loss: 0.1787 - val_accuracy: 0.7091\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9355 - val_loss: 0.1822 - val_accuracy: 0.7273\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9171 - val_loss: 0.1935 - val_accuracy: 0.6909\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.8894 - val_loss: 0.1858 - val_accuracy: 0.7091\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9124 - val_loss: 0.1872 - val_accuracy: 0.7091\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 0.9032 - val_loss: 0.1914 - val_accuracy: 0.6909\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9171 - val_loss: 0.1850 - val_accuracy: 0.7091\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9171 - val_loss: 0.1851 - val_accuracy: 0.7091\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9217 - val_loss: 0.1842 - val_accuracy: 0.7273\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9078 - val_loss: 0.1794 - val_accuracy: 0.7273\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9171 - val_loss: 0.1832 - val_accuracy: 0.7273\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9078 - val_loss: 0.1878 - val_accuracy: 0.6909\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.8848 - val_loss: 0.1839 - val_accuracy: 0.7273\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9171 - val_loss: 0.1808 - val_accuracy: 0.7273\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9217 - val_loss: 0.1857 - val_accuracy: 0.7455\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9401 - val_loss: 0.1928 - val_accuracy: 0.7273\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9032 - val_loss: 0.1862 - val_accuracy: 0.7091\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9355 - val_loss: 0.1794 - val_accuracy: 0.7455\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9355 - val_loss: 0.1775 - val_accuracy: 0.7455\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9355 - val_loss: 0.1931 - val_accuracy: 0.6909\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.9171 - val_loss: 0.1848 - val_accuracy: 0.7455\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9217 - val_loss: 0.1809 - val_accuracy: 0.7455\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9355 - val_loss: 0.1958 - val_accuracy: 0.7455\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0570 - accuracy: 0.9447 - val_loss: 0.1861 - val_accuracy: 0.7455\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9447 - val_loss: 0.1919 - val_accuracy: 0.7273\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.8894 - val_loss: 0.1906 - val_accuracy: 0.7273\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9447 - val_loss: 0.1969 - val_accuracy: 0.7091\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9217 - val_loss: 0.2029 - val_accuracy: 0.7091\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9355 - val_loss: 0.1958 - val_accuracy: 0.7455\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9401 - val_loss: 0.1910 - val_accuracy: 0.7455\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9309 - val_loss: 0.1873 - val_accuracy: 0.7273\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9217 - val_loss: 0.1906 - val_accuracy: 0.7273\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9263 - val_loss: 0.1887 - val_accuracy: 0.7273\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9309 - val_loss: 0.1804 - val_accuracy: 0.7273\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9447 - val_loss: 0.1858 - val_accuracy: 0.7273\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9355 - val_loss: 0.2016 - val_accuracy: 0.7455\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9309 - val_loss: 0.1929 - val_accuracy: 0.7273\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9263 - val_loss: 0.1909 - val_accuracy: 0.7273\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9493 - val_loss: 0.2097 - val_accuracy: 0.7091\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9078 - val_loss: 0.1946 - val_accuracy: 0.7273\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9171 - val_loss: 0.1925 - val_accuracy: 0.7273\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9217 - val_loss: 0.1961 - val_accuracy: 0.7273\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9217 - val_loss: 0.1908 - val_accuracy: 0.7273\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9309 - val_loss: 0.1897 - val_accuracy: 0.7273\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9217 - val_loss: 0.2013 - val_accuracy: 0.7273\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9447 - val_loss: 0.1923 - val_accuracy: 0.7091\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9217 - val_loss: 0.1819 - val_accuracy: 0.7273\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9447 - val_loss: 0.1824 - val_accuracy: 0.7273\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.8894 - val_loss: 0.1900 - val_accuracy: 0.7455\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9401 - val_loss: 0.1834 - val_accuracy: 0.7455\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.9631 - val_loss: 0.1870 - val_accuracy: 0.7455\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9401 - val_loss: 0.1883 - val_accuracy: 0.7273\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0584 - accuracy: 0.9217 - val_loss: 0.1949 - val_accuracy: 0.7455\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.9032 - val_loss: 0.1935 - val_accuracy: 0.7455\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9263 - val_loss: 0.1906 - val_accuracy: 0.7455\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9309 - val_loss: 0.1862 - val_accuracy: 0.7455\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9631 - val_loss: 0.1904 - val_accuracy: 0.7455\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9309 - val_loss: 0.1898 - val_accuracy: 0.7455\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9539 - val_loss: 0.1868 - val_accuracy: 0.7455\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9447 - val_loss: 0.1938 - val_accuracy: 0.7455\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0504 - accuracy: 0.9539 - val_loss: 0.1939 - val_accuracy: 0.7455\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9493 - val_loss: 0.1912 - val_accuracy: 0.7455\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9217 - val_loss: 0.1895 - val_accuracy: 0.7455\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9309 - val_loss: 0.1908 - val_accuracy: 0.7455\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9447 - val_loss: 0.1879 - val_accuracy: 0.7455\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9355 - val_loss: 0.1849 - val_accuracy: 0.7455\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9493 - val_loss: 0.1932 - val_accuracy: 0.7455\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9032 - val_loss: 0.1893 - val_accuracy: 0.7273\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9724 - val_loss: 0.1948 - val_accuracy: 0.7455\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9309 - val_loss: 0.1988 - val_accuracy: 0.7455\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9539 - val_loss: 0.2012 - val_accuracy: 0.7455\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9539 - val_loss: 0.1902 - val_accuracy: 0.7273\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9171 - val_loss: 0.1936 - val_accuracy: 0.7455\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9585 - val_loss: 0.1919 - val_accuracy: 0.7455\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.9309 - val_loss: 0.2001 - val_accuracy: 0.7273\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9171 - val_loss: 0.2002 - val_accuracy: 0.7273\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9171 - val_loss: 0.2002 - val_accuracy: 0.7455\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9539 - val_loss: 0.2043 - val_accuracy: 0.7273\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9309 - val_loss: 0.2003 - val_accuracy: 0.7455\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9493 - val_loss: 0.1966 - val_accuracy: 0.7455\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9447 - val_loss: 0.1960 - val_accuracy: 0.7455\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9539 - val_loss: 0.1958 - val_accuracy: 0.7455\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9355 - val_loss: 0.2016 - val_accuracy: 0.7455\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.9263 - val_loss: 0.1947 - val_accuracy: 0.7455\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9447 - val_loss: 0.1954 - val_accuracy: 0.7455\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9401 - val_loss: 0.1940 - val_accuracy: 0.7455\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9539 - val_loss: 0.1868 - val_accuracy: 0.7455\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9493 - val_loss: 0.1955 - val_accuracy: 0.7455\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9539 - val_loss: 0.1991 - val_accuracy: 0.7273\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9401 - val_loss: 0.1968 - val_accuracy: 0.7273\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9401 - val_loss: 0.2142 - val_accuracy: 0.7091\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9447 - val_loss: 0.2051 - val_accuracy: 0.7273\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0723 - accuracy: 0.9124 - val_loss: 0.1996 - val_accuracy: 0.7636\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9263 - val_loss: 0.1969 - val_accuracy: 0.7636\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9309 - val_loss: 0.1958 - val_accuracy: 0.7455\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9401 - val_loss: 0.2066 - val_accuracy: 0.7455\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9585 - val_loss: 0.2146 - val_accuracy: 0.7273\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9447 - val_loss: 0.2134 - val_accuracy: 0.7091\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9447 - val_loss: 0.2045 - val_accuracy: 0.7091\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9493 - val_loss: 0.2084 - val_accuracy: 0.7091\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9770 - val_loss: 0.2008 - val_accuracy: 0.7273\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9724 - val_loss: 0.2068 - val_accuracy: 0.7091\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9309 - val_loss: 0.2031 - val_accuracy: 0.7091\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9301\n",
            "accuracy: [0.05820036306977272, 0.9301470518112183]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 24ms/step - loss: 0.3123 - accuracy: 0.5576 - val_loss: 0.2985 - val_accuracy: 0.5636\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3048 - accuracy: 0.5806 - val_loss: 0.2709 - val_accuracy: 0.6000\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2578 - accuracy: 0.5945 - val_loss: 0.2565 - val_accuracy: 0.6364\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2269 - accuracy: 0.6590 - val_loss: 0.2410 - val_accuracy: 0.6364\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2153 - accuracy: 0.7235 - val_loss: 0.2387 - val_accuracy: 0.6545\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.7189 - val_loss: 0.2382 - val_accuracy: 0.6545\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.7235 - val_loss: 0.2367 - val_accuracy: 0.6545\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1782 - accuracy: 0.7419 - val_loss: 0.2289 - val_accuracy: 0.6545\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.7373 - val_loss: 0.2240 - val_accuracy: 0.6545\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1674 - accuracy: 0.7558 - val_loss: 0.2283 - val_accuracy: 0.6545\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.7558 - val_loss: 0.2241 - val_accuracy: 0.6364\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1780 - accuracy: 0.7419 - val_loss: 0.2186 - val_accuracy: 0.6364\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.7558 - val_loss: 0.2315 - val_accuracy: 0.6364\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1780 - accuracy: 0.7650 - val_loss: 0.2201 - val_accuracy: 0.6545\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.7880 - val_loss: 0.2148 - val_accuracy: 0.6727\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.7650 - val_loss: 0.2088 - val_accuracy: 0.6545\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1581 - accuracy: 0.7742 - val_loss: 0.2104 - val_accuracy: 0.6545\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1600 - accuracy: 0.7834 - val_loss: 0.2139 - val_accuracy: 0.6364\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1465 - accuracy: 0.7926 - val_loss: 0.2066 - val_accuracy: 0.6364\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.8065 - val_loss: 0.2087 - val_accuracy: 0.6364\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.7742 - val_loss: 0.2209 - val_accuracy: 0.6182\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.8111 - val_loss: 0.2213 - val_accuracy: 0.6182\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.8479 - val_loss: 0.2035 - val_accuracy: 0.6727\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.7972 - val_loss: 0.1979 - val_accuracy: 0.7091\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.7972 - val_loss: 0.2056 - val_accuracy: 0.6545\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.8111 - val_loss: 0.2061 - val_accuracy: 0.6545\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.8157 - val_loss: 0.2018 - val_accuracy: 0.6727\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.8065 - val_loss: 0.1975 - val_accuracy: 0.6909\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.8203 - val_loss: 0.1967 - val_accuracy: 0.6909\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.8018 - val_loss: 0.1996 - val_accuracy: 0.6909\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.7926 - val_loss: 0.2016 - val_accuracy: 0.6727\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1295 - accuracy: 0.8433 - val_loss: 0.1975 - val_accuracy: 0.6727\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.8341 - val_loss: 0.1917 - val_accuracy: 0.6909\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.8479 - val_loss: 0.1991 - val_accuracy: 0.6545\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.8387 - val_loss: 0.2079 - val_accuracy: 0.6909\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.8203 - val_loss: 0.2089 - val_accuracy: 0.6909\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.8157 - val_loss: 0.1920 - val_accuracy: 0.7091\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.8341 - val_loss: 0.1888 - val_accuracy: 0.7273\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.8756 - val_loss: 0.1893 - val_accuracy: 0.7091\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.8525 - val_loss: 0.1909 - val_accuracy: 0.7091\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1240 - accuracy: 0.8433 - val_loss: 0.1878 - val_accuracy: 0.7091\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1159 - accuracy: 0.8433 - val_loss: 0.1906 - val_accuracy: 0.7091\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1198 - accuracy: 0.8479 - val_loss: 0.1974 - val_accuracy: 0.7091\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1097 - accuracy: 0.8525 - val_loss: 0.1906 - val_accuracy: 0.7091\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.8664 - val_loss: 0.1920 - val_accuracy: 0.7091\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.8571 - val_loss: 0.1966 - val_accuracy: 0.7091\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.8664 - val_loss: 0.1988 - val_accuracy: 0.7455\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.8664 - val_loss: 0.1978 - val_accuracy: 0.7091\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.8295 - val_loss: 0.1951 - val_accuracy: 0.7091\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.8756 - val_loss: 0.1929 - val_accuracy: 0.7091\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.8571 - val_loss: 0.1997 - val_accuracy: 0.6909\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.8756 - val_loss: 0.2016 - val_accuracy: 0.6909\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.8618 - val_loss: 0.1987 - val_accuracy: 0.6909\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1059 - accuracy: 0.8710 - val_loss: 0.1990 - val_accuracy: 0.7091\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.8433 - val_loss: 0.2026 - val_accuracy: 0.6909\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.8664 - val_loss: 0.2130 - val_accuracy: 0.6909\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.8387 - val_loss: 0.2050 - val_accuracy: 0.7091\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 0.8525 - val_loss: 0.1970 - val_accuracy: 0.6909\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.8756 - val_loss: 0.2015 - val_accuracy: 0.7273\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.8664 - val_loss: 0.2023 - val_accuracy: 0.6727\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.8664 - val_loss: 0.2010 - val_accuracy: 0.6909\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.8710 - val_loss: 0.1939 - val_accuracy: 0.6909\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.8664 - val_loss: 0.1965 - val_accuracy: 0.7091\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.8802 - val_loss: 0.2025 - val_accuracy: 0.6727\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.8664 - val_loss: 0.1969 - val_accuracy: 0.6727\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.8756 - val_loss: 0.1966 - val_accuracy: 0.6727\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1003 - accuracy: 0.8710 - val_loss: 0.2021 - val_accuracy: 0.6909\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0922 - accuracy: 0.8756 - val_loss: 0.1983 - val_accuracy: 0.6909\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9032 - val_loss: 0.1976 - val_accuracy: 0.6909\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.8618 - val_loss: 0.1935 - val_accuracy: 0.7091\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9171 - val_loss: 0.2011 - val_accuracy: 0.7091\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0920 - accuracy: 0.8894 - val_loss: 0.1972 - val_accuracy: 0.6909\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.8894 - val_loss: 0.1975 - val_accuracy: 0.7091\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.8894 - val_loss: 0.1942 - val_accuracy: 0.6909\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.8756 - val_loss: 0.1925 - val_accuracy: 0.6727\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0926 - accuracy: 0.8986 - val_loss: 0.1953 - val_accuracy: 0.6909\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.8940 - val_loss: 0.1991 - val_accuracy: 0.6909\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.8894 - val_loss: 0.2073 - val_accuracy: 0.6909\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9032 - val_loss: 0.1994 - val_accuracy: 0.7091\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9032 - val_loss: 0.1974 - val_accuracy: 0.6909\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.8894 - val_loss: 0.2020 - val_accuracy: 0.6909\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.8710 - val_loss: 0.2004 - val_accuracy: 0.6909\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.8848 - val_loss: 0.2000 - val_accuracy: 0.7091\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9032 - val_loss: 0.1992 - val_accuracy: 0.7091\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9032 - val_loss: 0.1998 - val_accuracy: 0.7091\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.8756 - val_loss: 0.2020 - val_accuracy: 0.6909\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.8940 - val_loss: 0.2042 - val_accuracy: 0.6909\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.8986 - val_loss: 0.2039 - val_accuracy: 0.7091\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.8894 - val_loss: 0.2017 - val_accuracy: 0.7091\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0853 - accuracy: 0.8848 - val_loss: 0.2006 - val_accuracy: 0.7091\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.8940 - val_loss: 0.1991 - val_accuracy: 0.7091\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.8940 - val_loss: 0.1992 - val_accuracy: 0.7091\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.8940 - val_loss: 0.2000 - val_accuracy: 0.7091\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.8848 - val_loss: 0.1957 - val_accuracy: 0.7091\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.8756 - val_loss: 0.1955 - val_accuracy: 0.7091\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.8986 - val_loss: 0.2012 - val_accuracy: 0.6909\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9124 - val_loss: 0.1924 - val_accuracy: 0.6909\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9078 - val_loss: 0.1954 - val_accuracy: 0.6909\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9078 - val_loss: 0.1961 - val_accuracy: 0.7091\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9217 - val_loss: 0.1961 - val_accuracy: 0.7091\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9217 - val_loss: 0.1944 - val_accuracy: 0.6909\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9263 - val_loss: 0.1947 - val_accuracy: 0.6909\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 0.8986 - val_loss: 0.1922 - val_accuracy: 0.6909\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9124 - val_loss: 0.1936 - val_accuracy: 0.7091\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9124 - val_loss: 0.2010 - val_accuracy: 0.6909\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.8894 - val_loss: 0.1905 - val_accuracy: 0.7091\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9078 - val_loss: 0.1962 - val_accuracy: 0.7091\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9355 - val_loss: 0.2009 - val_accuracy: 0.7091\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9171 - val_loss: 0.1981 - val_accuracy: 0.7091\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9217 - val_loss: 0.1942 - val_accuracy: 0.7091\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9309 - val_loss: 0.1948 - val_accuracy: 0.7091\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0713 - accuracy: 0.9171 - val_loss: 0.1983 - val_accuracy: 0.7091\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9263 - val_loss: 0.1959 - val_accuracy: 0.7091\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.8894 - val_loss: 0.1942 - val_accuracy: 0.7091\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0746 - accuracy: 0.9078 - val_loss: 0.1968 - val_accuracy: 0.7091\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9401 - val_loss: 0.2122 - val_accuracy: 0.6909\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9217 - val_loss: 0.2044 - val_accuracy: 0.6909\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9171 - val_loss: 0.2002 - val_accuracy: 0.7273\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.9309 - val_loss: 0.2031 - val_accuracy: 0.6909\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0682 - accuracy: 0.9309 - val_loss: 0.2039 - val_accuracy: 0.6909\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9309 - val_loss: 0.2028 - val_accuracy: 0.6909\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0845 - accuracy: 0.8940 - val_loss: 0.2045 - val_accuracy: 0.6909\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9032 - val_loss: 0.2059 - val_accuracy: 0.6909\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9263 - val_loss: 0.2102 - val_accuracy: 0.6909\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9171 - val_loss: 0.1969 - val_accuracy: 0.6909\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9309 - val_loss: 0.2017 - val_accuracy: 0.6909\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9355 - val_loss: 0.2005 - val_accuracy: 0.6909\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9217 - val_loss: 0.1979 - val_accuracy: 0.7091\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9401 - val_loss: 0.1999 - val_accuracy: 0.7091\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9078 - val_loss: 0.2097 - val_accuracy: 0.6909\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9355 - val_loss: 0.2102 - val_accuracy: 0.6909\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9309 - val_loss: 0.2060 - val_accuracy: 0.6909\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9217 - val_loss: 0.2081 - val_accuracy: 0.6909\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9032 - val_loss: 0.2088 - val_accuracy: 0.6909\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9263 - val_loss: 0.2129 - val_accuracy: 0.6909\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9401 - val_loss: 0.2058 - val_accuracy: 0.6909\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9401 - val_loss: 0.2085 - val_accuracy: 0.6909\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0589 - accuracy: 0.9355 - val_loss: 0.2076 - val_accuracy: 0.6909\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9171 - val_loss: 0.2108 - val_accuracy: 0.6909\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9309 - val_loss: 0.2128 - val_accuracy: 0.6727\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9401 - val_loss: 0.2092 - val_accuracy: 0.6727\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9124 - val_loss: 0.2067 - val_accuracy: 0.6909\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9171 - val_loss: 0.2051 - val_accuracy: 0.6909\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9171 - val_loss: 0.2040 - val_accuracy: 0.6909\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9263 - val_loss: 0.2062 - val_accuracy: 0.6909\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9355 - val_loss: 0.2078 - val_accuracy: 0.6727\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0697 - accuracy: 0.9124 - val_loss: 0.2135 - val_accuracy: 0.6727\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.8986 - val_loss: 0.2125 - val_accuracy: 0.6727\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9355 - val_loss: 0.2177 - val_accuracy: 0.6727\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9263 - val_loss: 0.2122 - val_accuracy: 0.6727\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9124 - val_loss: 0.2111 - val_accuracy: 0.6727\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9217 - val_loss: 0.2166 - val_accuracy: 0.6727\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9217 - val_loss: 0.2112 - val_accuracy: 0.6727\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9171 - val_loss: 0.2105 - val_accuracy: 0.6727\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9263 - val_loss: 0.2092 - val_accuracy: 0.6727\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 0.9124 - val_loss: 0.2087 - val_accuracy: 0.6909\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9217 - val_loss: 0.2067 - val_accuracy: 0.6909\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9401 - val_loss: 0.2150 - val_accuracy: 0.6545\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9355 - val_loss: 0.2077 - val_accuracy: 0.6909\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9217 - val_loss: 0.2026 - val_accuracy: 0.6909\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9355 - val_loss: 0.2019 - val_accuracy: 0.6909\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9447 - val_loss: 0.1990 - val_accuracy: 0.6909\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9263 - val_loss: 0.2010 - val_accuracy: 0.6727\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9263 - val_loss: 0.2025 - val_accuracy: 0.7091\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0664 - accuracy: 0.9217 - val_loss: 0.2104 - val_accuracy: 0.6909\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9171 - val_loss: 0.2132 - val_accuracy: 0.7091\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9309 - val_loss: 0.2225 - val_accuracy: 0.6545\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9355 - val_loss: 0.2169 - val_accuracy: 0.6909\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9401 - val_loss: 0.2161 - val_accuracy: 0.7091\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9171 - val_loss: 0.2131 - val_accuracy: 0.7091\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0523 - accuracy: 0.9447 - val_loss: 0.2072 - val_accuracy: 0.7273\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9585 - val_loss: 0.2112 - val_accuracy: 0.7091\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9447 - val_loss: 0.2155 - val_accuracy: 0.6545\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.9217 - val_loss: 0.2095 - val_accuracy: 0.6909\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9217 - val_loss: 0.2118 - val_accuracy: 0.6727\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9309 - val_loss: 0.2112 - val_accuracy: 0.6727\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9171 - val_loss: 0.2076 - val_accuracy: 0.6727\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9309 - val_loss: 0.2030 - val_accuracy: 0.6727\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9355 - val_loss: 0.2078 - val_accuracy: 0.6909\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9263 - val_loss: 0.2092 - val_accuracy: 0.6909\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9263 - val_loss: 0.2158 - val_accuracy: 0.6727\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9263 - val_loss: 0.2183 - val_accuracy: 0.6727\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9447 - val_loss: 0.2250 - val_accuracy: 0.6909\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9539 - val_loss: 0.2258 - val_accuracy: 0.6909\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9217 - val_loss: 0.2250 - val_accuracy: 0.6909\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9309 - val_loss: 0.2173 - val_accuracy: 0.6909\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9539 - val_loss: 0.2219 - val_accuracy: 0.6909\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0514 - accuracy: 0.9401 - val_loss: 0.2186 - val_accuracy: 0.6909\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0533 - accuracy: 0.9447 - val_loss: 0.2156 - val_accuracy: 0.6909\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9171 - val_loss: 0.2051 - val_accuracy: 0.6727\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9355 - val_loss: 0.2188 - val_accuracy: 0.6909\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9447 - val_loss: 0.2111 - val_accuracy: 0.6909\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9355 - val_loss: 0.2052 - val_accuracy: 0.6909\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.9217 - val_loss: 0.2107 - val_accuracy: 0.6909\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0633 - accuracy: 0.9263 - val_loss: 0.2117 - val_accuracy: 0.6909\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9539 - val_loss: 0.2135 - val_accuracy: 0.6727\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9355 - val_loss: 0.2085 - val_accuracy: 0.6909\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9309 - val_loss: 0.2100 - val_accuracy: 0.6909\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9124 - val_loss: 0.2096 - val_accuracy: 0.6909\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9447 - val_loss: 0.2063 - val_accuracy: 0.6909\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9081\n",
            "accuracy: [0.06739254295825958, 0.908088207244873]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 22ms/step - loss: 0.4069 - accuracy: 0.5346 - val_loss: 0.3528 - val_accuracy: 0.4909\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2946 - accuracy: 0.6037 - val_loss: 0.3204 - val_accuracy: 0.4909\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2731 - accuracy: 0.5991 - val_loss: 0.3063 - val_accuracy: 0.5091\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.6083 - val_loss: 0.2918 - val_accuracy: 0.5455\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2365 - accuracy: 0.6498 - val_loss: 0.2757 - val_accuracy: 0.5636\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.6728 - val_loss: 0.2664 - val_accuracy: 0.6000\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.7235 - val_loss: 0.2590 - val_accuracy: 0.6182\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1779 - accuracy: 0.7419 - val_loss: 0.2529 - val_accuracy: 0.6000\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1810 - accuracy: 0.7604 - val_loss: 0.2452 - val_accuracy: 0.6182\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1989 - accuracy: 0.7327 - val_loss: 0.2428 - val_accuracy: 0.6000\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.7696 - val_loss: 0.2455 - val_accuracy: 0.6727\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.7373 - val_loss: 0.2353 - val_accuracy: 0.6545\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.7465 - val_loss: 0.2339 - val_accuracy: 0.6545\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1613 - accuracy: 0.7373 - val_loss: 0.2328 - val_accuracy: 0.6727\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.7742 - val_loss: 0.2258 - val_accuracy: 0.6909\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1644 - accuracy: 0.7465 - val_loss: 0.2254 - val_accuracy: 0.6545\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1416 - accuracy: 0.7926 - val_loss: 0.2239 - val_accuracy: 0.6545\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1430 - accuracy: 0.8111 - val_loss: 0.2271 - val_accuracy: 0.6727\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1414 - accuracy: 0.7926 - val_loss: 0.2309 - val_accuracy: 0.6727\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.8018 - val_loss: 0.2306 - val_accuracy: 0.6545\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.8065 - val_loss: 0.2204 - val_accuracy: 0.6727\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.8295 - val_loss: 0.2165 - val_accuracy: 0.7091\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.8018 - val_loss: 0.2175 - val_accuracy: 0.7091\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.8203 - val_loss: 0.2282 - val_accuracy: 0.6909\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1263 - accuracy: 0.8341 - val_loss: 0.2300 - val_accuracy: 0.6909\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.8479 - val_loss: 0.2182 - val_accuracy: 0.7636\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.8341 - val_loss: 0.2151 - val_accuracy: 0.7091\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.8664 - val_loss: 0.2207 - val_accuracy: 0.6909\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.8341 - val_loss: 0.2121 - val_accuracy: 0.7273\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.8756 - val_loss: 0.2090 - val_accuracy: 0.7273\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.8618 - val_loss: 0.2057 - val_accuracy: 0.7273\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1274 - accuracy: 0.8479 - val_loss: 0.1982 - val_accuracy: 0.7455\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.8433 - val_loss: 0.1939 - val_accuracy: 0.7455\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.8664 - val_loss: 0.2012 - val_accuracy: 0.7455\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.8525 - val_loss: 0.1957 - val_accuracy: 0.7636\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1056 - accuracy: 0.8664 - val_loss: 0.2014 - val_accuracy: 0.7818\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.8065 - val_loss: 0.1979 - val_accuracy: 0.7636\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.8479 - val_loss: 0.1939 - val_accuracy: 0.7636\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.8802 - val_loss: 0.2034 - val_accuracy: 0.7636\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.8894 - val_loss: 0.2069 - val_accuracy: 0.7091\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.8802 - val_loss: 0.2112 - val_accuracy: 0.6727\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.8802 - val_loss: 0.2026 - val_accuracy: 0.7455\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.8802 - val_loss: 0.2023 - val_accuracy: 0.7455\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.8710 - val_loss: 0.2002 - val_accuracy: 0.7455\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.8756 - val_loss: 0.2016 - val_accuracy: 0.7455\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1081 - accuracy: 0.8756 - val_loss: 0.2041 - val_accuracy: 0.7273\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.8986 - val_loss: 0.2153 - val_accuracy: 0.6909\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.8986 - val_loss: 0.2109 - val_accuracy: 0.6909\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1092 - accuracy: 0.8618 - val_loss: 0.2007 - val_accuracy: 0.7273\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.8894 - val_loss: 0.1965 - val_accuracy: 0.7273\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0944 - accuracy: 0.8940 - val_loss: 0.1957 - val_accuracy: 0.7273\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.8986 - val_loss: 0.1946 - val_accuracy: 0.7273\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.8986 - val_loss: 0.2011 - val_accuracy: 0.7091\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.8894 - val_loss: 0.2028 - val_accuracy: 0.7273\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.8940 - val_loss: 0.2006 - val_accuracy: 0.7273\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.8986 - val_loss: 0.1985 - val_accuracy: 0.7091\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.8802 - val_loss: 0.2052 - val_accuracy: 0.6909\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.8664 - val_loss: 0.2106 - val_accuracy: 0.6909\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.9217 - val_loss: 0.2097 - val_accuracy: 0.6727\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.8986 - val_loss: 0.2038 - val_accuracy: 0.6727\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9217 - val_loss: 0.2036 - val_accuracy: 0.6727\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.8894 - val_loss: 0.1996 - val_accuracy: 0.6727\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9124 - val_loss: 0.1980 - val_accuracy: 0.7091\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.8986 - val_loss: 0.2011 - val_accuracy: 0.7091\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.8940 - val_loss: 0.1958 - val_accuracy: 0.7273\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9171 - val_loss: 0.2000 - val_accuracy: 0.6909\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9263 - val_loss: 0.2024 - val_accuracy: 0.6727\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9032 - val_loss: 0.2004 - val_accuracy: 0.6727\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0799 - accuracy: 0.9171 - val_loss: 0.2013 - val_accuracy: 0.6909\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9124 - val_loss: 0.2024 - val_accuracy: 0.7091\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9447 - val_loss: 0.2030 - val_accuracy: 0.7091\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.8986 - val_loss: 0.2064 - val_accuracy: 0.7091\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0764 - accuracy: 0.9171 - val_loss: 0.2139 - val_accuracy: 0.6909\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.8986 - val_loss: 0.2018 - val_accuracy: 0.7273\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9032 - val_loss: 0.2034 - val_accuracy: 0.7091\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9171 - val_loss: 0.2077 - val_accuracy: 0.7091\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.8848 - val_loss: 0.2012 - val_accuracy: 0.7091\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.8986 - val_loss: 0.2008 - val_accuracy: 0.7091\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9124 - val_loss: 0.2043 - val_accuracy: 0.6727\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.8986 - val_loss: 0.2064 - val_accuracy: 0.6727\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9078 - val_loss: 0.2025 - val_accuracy: 0.6909\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9217 - val_loss: 0.2055 - val_accuracy: 0.6909\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0767 - accuracy: 0.9171 - val_loss: 0.2004 - val_accuracy: 0.7091\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9124 - val_loss: 0.2021 - val_accuracy: 0.7091\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9124 - val_loss: 0.2071 - val_accuracy: 0.7091\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9078 - val_loss: 0.2139 - val_accuracy: 0.7091\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.9263 - val_loss: 0.2172 - val_accuracy: 0.7091\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9309 - val_loss: 0.2099 - val_accuracy: 0.6909\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9217 - val_loss: 0.2103 - val_accuracy: 0.6727\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9263 - val_loss: 0.2150 - val_accuracy: 0.6727\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9078 - val_loss: 0.2178 - val_accuracy: 0.6909\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9217 - val_loss: 0.2101 - val_accuracy: 0.6727\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.8986 - val_loss: 0.2182 - val_accuracy: 0.6909\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0644 - accuracy: 0.9263 - val_loss: 0.2253 - val_accuracy: 0.6727\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0746 - accuracy: 0.9263 - val_loss: 0.2265 - val_accuracy: 0.6727\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9263 - val_loss: 0.2165 - val_accuracy: 0.6909\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9124 - val_loss: 0.2177 - val_accuracy: 0.6909\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9309 - val_loss: 0.2201 - val_accuracy: 0.6909\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9217 - val_loss: 0.2225 - val_accuracy: 0.6909\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0672 - accuracy: 0.9309 - val_loss: 0.2062 - val_accuracy: 0.7091\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9124 - val_loss: 0.2094 - val_accuracy: 0.7091\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9401 - val_loss: 0.2249 - val_accuracy: 0.6909\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9171 - val_loss: 0.2241 - val_accuracy: 0.7091\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9217 - val_loss: 0.2192 - val_accuracy: 0.7091\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9309 - val_loss: 0.2263 - val_accuracy: 0.7091\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9355 - val_loss: 0.2308 - val_accuracy: 0.6727\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9263 - val_loss: 0.2252 - val_accuracy: 0.7091\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9263 - val_loss: 0.2284 - val_accuracy: 0.6727\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 0.9263 - val_loss: 0.2238 - val_accuracy: 0.6909\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9217 - val_loss: 0.2240 - val_accuracy: 0.7091\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9309 - val_loss: 0.2200 - val_accuracy: 0.6909\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9078 - val_loss: 0.2220 - val_accuracy: 0.7091\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.9078 - val_loss: 0.2263 - val_accuracy: 0.6909\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9171 - val_loss: 0.2255 - val_accuracy: 0.6909\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9217 - val_loss: 0.2278 - val_accuracy: 0.6909\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9447 - val_loss: 0.2239 - val_accuracy: 0.6909\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9217 - val_loss: 0.2187 - val_accuracy: 0.6909\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9401 - val_loss: 0.2277 - val_accuracy: 0.7091\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9309 - val_loss: 0.2291 - val_accuracy: 0.6909\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9355 - val_loss: 0.2239 - val_accuracy: 0.6909\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9355 - val_loss: 0.2198 - val_accuracy: 0.7091\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9447 - val_loss: 0.2321 - val_accuracy: 0.6909\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9263 - val_loss: 0.2294 - val_accuracy: 0.6909\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9124 - val_loss: 0.2222 - val_accuracy: 0.7091\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9263 - val_loss: 0.2335 - val_accuracy: 0.7091\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0650 - accuracy: 0.9309 - val_loss: 0.2329 - val_accuracy: 0.7091\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9309 - val_loss: 0.2293 - val_accuracy: 0.7091\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9585 - val_loss: 0.2308 - val_accuracy: 0.6909\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9447 - val_loss: 0.2330 - val_accuracy: 0.6909\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9263 - val_loss: 0.2306 - val_accuracy: 0.6909\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9217 - val_loss: 0.2242 - val_accuracy: 0.6909\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9401 - val_loss: 0.2269 - val_accuracy: 0.6909\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9078 - val_loss: 0.2348 - val_accuracy: 0.7091\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9401 - val_loss: 0.2393 - val_accuracy: 0.6909\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9355 - val_loss: 0.2341 - val_accuracy: 0.6909\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9401 - val_loss: 0.2398 - val_accuracy: 0.6909\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9447 - val_loss: 0.2264 - val_accuracy: 0.6909\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9355 - val_loss: 0.2230 - val_accuracy: 0.7091\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9263 - val_loss: 0.2246 - val_accuracy: 0.7091\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9263 - val_loss: 0.2299 - val_accuracy: 0.6909\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9401 - val_loss: 0.2275 - val_accuracy: 0.7091\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9355 - val_loss: 0.2330 - val_accuracy: 0.6727\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9401 - val_loss: 0.2304 - val_accuracy: 0.6909\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9355 - val_loss: 0.2373 - val_accuracy: 0.6727\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9217 - val_loss: 0.2244 - val_accuracy: 0.7091\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9171 - val_loss: 0.2189 - val_accuracy: 0.7091\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9585 - val_loss: 0.2277 - val_accuracy: 0.6909\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9631 - val_loss: 0.2352 - val_accuracy: 0.6909\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.9217 - val_loss: 0.2281 - val_accuracy: 0.6909\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9355 - val_loss: 0.2285 - val_accuracy: 0.6909\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9263 - val_loss: 0.2348 - val_accuracy: 0.6727\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9493 - val_loss: 0.2300 - val_accuracy: 0.6727\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9124 - val_loss: 0.2275 - val_accuracy: 0.6727\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9355 - val_loss: 0.2304 - val_accuracy: 0.6727\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9401 - val_loss: 0.2309 - val_accuracy: 0.6545\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9309 - val_loss: 0.2294 - val_accuracy: 0.6545\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9401 - val_loss: 0.2256 - val_accuracy: 0.6909\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9401 - val_loss: 0.2356 - val_accuracy: 0.6909\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9309 - val_loss: 0.2318 - val_accuracy: 0.6909\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9217 - val_loss: 0.2263 - val_accuracy: 0.7091\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9309 - val_loss: 0.2253 - val_accuracy: 0.7091\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9309 - val_loss: 0.2329 - val_accuracy: 0.6909\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0514 - accuracy: 0.9447 - val_loss: 0.2299 - val_accuracy: 0.6909\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9401 - val_loss: 0.2314 - val_accuracy: 0.6909\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9447 - val_loss: 0.2296 - val_accuracy: 0.6909\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9631 - val_loss: 0.2313 - val_accuracy: 0.6909\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9171 - val_loss: 0.2359 - val_accuracy: 0.6909\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9309 - val_loss: 0.2381 - val_accuracy: 0.6727\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9401 - val_loss: 0.2297 - val_accuracy: 0.6909\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9309 - val_loss: 0.2305 - val_accuracy: 0.7091\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9217 - val_loss: 0.2286 - val_accuracy: 0.6909\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9539 - val_loss: 0.2252 - val_accuracy: 0.6909\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9309 - val_loss: 0.2260 - val_accuracy: 0.6909\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.9217 - val_loss: 0.2282 - val_accuracy: 0.6909\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9263 - val_loss: 0.2286 - val_accuracy: 0.6909\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9355 - val_loss: 0.2339 - val_accuracy: 0.6727\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9401 - val_loss: 0.2330 - val_accuracy: 0.6727\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9309 - val_loss: 0.2359 - val_accuracy: 0.6727\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9493 - val_loss: 0.2318 - val_accuracy: 0.6727\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9447 - val_loss: 0.2285 - val_accuracy: 0.6727\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.9309 - val_loss: 0.2380 - val_accuracy: 0.6727\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9355 - val_loss: 0.2395 - val_accuracy: 0.6727\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9309 - val_loss: 0.2292 - val_accuracy: 0.6727\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9263 - val_loss: 0.2235 - val_accuracy: 0.6909\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9263 - val_loss: 0.2343 - val_accuracy: 0.6727\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9309 - val_loss: 0.2376 - val_accuracy: 0.6727\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9355 - val_loss: 0.2276 - val_accuracy: 0.6727\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9539 - val_loss: 0.2248 - val_accuracy: 0.6727\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9355 - val_loss: 0.2245 - val_accuracy: 0.6909\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9447 - val_loss: 0.2321 - val_accuracy: 0.6909\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0504 - accuracy: 0.9401 - val_loss: 0.2277 - val_accuracy: 0.6727\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9401 - val_loss: 0.2260 - val_accuracy: 0.6909\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9401 - val_loss: 0.2307 - val_accuracy: 0.6727\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.9493 - val_loss: 0.2293 - val_accuracy: 0.6727\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9585 - val_loss: 0.2288 - val_accuracy: 0.6727\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9309 - val_loss: 0.2272 - val_accuracy: 0.6727\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9447 - val_loss: 0.2272 - val_accuracy: 0.6727\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9401 - val_loss: 0.2242 - val_accuracy: 0.6727\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9493 - val_loss: 0.2206 - val_accuracy: 0.6727\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9447 - val_loss: 0.2239 - val_accuracy: 0.6727\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9081\n",
            "accuracy: [0.06864585727453232, 0.908088207244873]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 23ms/step - loss: 0.3626 - accuracy: 0.4654 - val_loss: 0.3345 - val_accuracy: 0.4909\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.5346 - val_loss: 0.2910 - val_accuracy: 0.4909\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2461 - accuracy: 0.6313 - val_loss: 0.2685 - val_accuracy: 0.5818\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.6590 - val_loss: 0.2558 - val_accuracy: 0.6545\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2283 - accuracy: 0.6682 - val_loss: 0.2488 - val_accuracy: 0.6727\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2216 - accuracy: 0.6682 - val_loss: 0.2434 - val_accuracy: 0.7091\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.6774 - val_loss: 0.2365 - val_accuracy: 0.6909\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2082 - accuracy: 0.7097 - val_loss: 0.2307 - val_accuracy: 0.6909\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2050 - accuracy: 0.6866 - val_loss: 0.2263 - val_accuracy: 0.6909\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1950 - accuracy: 0.6866 - val_loss: 0.2265 - val_accuracy: 0.7091\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1877 - accuracy: 0.7005 - val_loss: 0.2214 - val_accuracy: 0.6545\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.7604 - val_loss: 0.2192 - val_accuracy: 0.6545\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.7327 - val_loss: 0.2198 - val_accuracy: 0.6545\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.7604 - val_loss: 0.2169 - val_accuracy: 0.6727\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1625 - accuracy: 0.7696 - val_loss: 0.2136 - val_accuracy: 0.6727\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1714 - accuracy: 0.7419 - val_loss: 0.2094 - val_accuracy: 0.6727\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.7650 - val_loss: 0.2047 - val_accuracy: 0.6909\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.7880 - val_loss: 0.2009 - val_accuracy: 0.6727\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.7880 - val_loss: 0.2001 - val_accuracy: 0.6364\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1503 - accuracy: 0.7742 - val_loss: 0.1993 - val_accuracy: 0.6364\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.8249 - val_loss: 0.1991 - val_accuracy: 0.6727\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1456 - accuracy: 0.7880 - val_loss: 0.2031 - val_accuracy: 0.6545\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 0.7834 - val_loss: 0.2057 - val_accuracy: 0.6727\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1462 - accuracy: 0.7926 - val_loss: 0.2111 - val_accuracy: 0.6545\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1444 - accuracy: 0.8111 - val_loss: 0.2097 - val_accuracy: 0.6545\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.7880 - val_loss: 0.2058 - val_accuracy: 0.6727\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1425 - accuracy: 0.8249 - val_loss: 0.2003 - val_accuracy: 0.6545\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1330 - accuracy: 0.8249 - val_loss: 0.2002 - val_accuracy: 0.6545\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.8710 - val_loss: 0.1998 - val_accuracy: 0.6909\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.8295 - val_loss: 0.2002 - val_accuracy: 0.7091\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.8433 - val_loss: 0.1985 - val_accuracy: 0.7091\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.8157 - val_loss: 0.2010 - val_accuracy: 0.6727\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.8479 - val_loss: 0.1997 - val_accuracy: 0.7091\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.8664 - val_loss: 0.2005 - val_accuracy: 0.6909\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.8525 - val_loss: 0.1992 - val_accuracy: 0.6909\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.8479 - val_loss: 0.1985 - val_accuracy: 0.6909\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1254 - accuracy: 0.8249 - val_loss: 0.2037 - val_accuracy: 0.7091\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.8525 - val_loss: 0.2047 - val_accuracy: 0.6909\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.8571 - val_loss: 0.2072 - val_accuracy: 0.6909\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.8571 - val_loss: 0.2064 - val_accuracy: 0.6909\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1130 - accuracy: 0.8710 - val_loss: 0.2009 - val_accuracy: 0.6909\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.8756 - val_loss: 0.1963 - val_accuracy: 0.7273\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1111 - accuracy: 0.8664 - val_loss: 0.1992 - val_accuracy: 0.7091\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.8525 - val_loss: 0.2010 - val_accuracy: 0.7091\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.8618 - val_loss: 0.2033 - val_accuracy: 0.7273\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.8571 - val_loss: 0.2046 - val_accuracy: 0.7091\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.8479 - val_loss: 0.2051 - val_accuracy: 0.6909\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.8756 - val_loss: 0.2084 - val_accuracy: 0.6909\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.8525 - val_loss: 0.2089 - val_accuracy: 0.7091\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.8664 - val_loss: 0.2111 - val_accuracy: 0.7091\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.8618 - val_loss: 0.2108 - val_accuracy: 0.6909\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.8664 - val_loss: 0.2133 - val_accuracy: 0.6727\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.8249 - val_loss: 0.2093 - val_accuracy: 0.6727\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.8802 - val_loss: 0.2068 - val_accuracy: 0.6909\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.8664 - val_loss: 0.2047 - val_accuracy: 0.6909\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.8618 - val_loss: 0.2034 - val_accuracy: 0.6545\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.8848 - val_loss: 0.2093 - val_accuracy: 0.6727\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.8571 - val_loss: 0.2067 - val_accuracy: 0.6727\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.8848 - val_loss: 0.2034 - val_accuracy: 0.6727\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.8618 - val_loss: 0.2056 - val_accuracy: 0.6727\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.8571 - val_loss: 0.2076 - val_accuracy: 0.6545\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.8525 - val_loss: 0.2119 - val_accuracy: 0.6727\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.8525 - val_loss: 0.2114 - val_accuracy: 0.6727\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.8664 - val_loss: 0.2116 - val_accuracy: 0.6545\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.8618 - val_loss: 0.2106 - val_accuracy: 0.6727\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.8802 - val_loss: 0.2121 - val_accuracy: 0.6545\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0998 - accuracy: 0.8664 - val_loss: 0.2130 - val_accuracy: 0.6545\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.8986 - val_loss: 0.2121 - val_accuracy: 0.6727\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.8940 - val_loss: 0.2184 - val_accuracy: 0.6545\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.8940 - val_loss: 0.2178 - val_accuracy: 0.6545\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.8894 - val_loss: 0.2144 - val_accuracy: 0.6545\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9032 - val_loss: 0.2070 - val_accuracy: 0.6545\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.8848 - val_loss: 0.2059 - val_accuracy: 0.6727\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9217 - val_loss: 0.2029 - val_accuracy: 0.6545\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.8894 - val_loss: 0.2069 - val_accuracy: 0.6545\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 0.8848 - val_loss: 0.2094 - val_accuracy: 0.6727\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.8802 - val_loss: 0.2120 - val_accuracy: 0.6364\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0941 - accuracy: 0.8664 - val_loss: 0.2165 - val_accuracy: 0.6364\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9032 - val_loss: 0.2129 - val_accuracy: 0.6545\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.8986 - val_loss: 0.2120 - val_accuracy: 0.6545\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.8848 - val_loss: 0.2099 - val_accuracy: 0.6727\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0882 - accuracy: 0.8894 - val_loss: 0.2178 - val_accuracy: 0.6727\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.8894 - val_loss: 0.2152 - val_accuracy: 0.6545\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.8525 - val_loss: 0.2159 - val_accuracy: 0.6727\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.8940 - val_loss: 0.2170 - val_accuracy: 0.6909\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.8894 - val_loss: 0.2164 - val_accuracy: 0.6909\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9171 - val_loss: 0.2133 - val_accuracy: 0.6727\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.8848 - val_loss: 0.2176 - val_accuracy: 0.7091\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.8802 - val_loss: 0.2181 - val_accuracy: 0.6909\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9032 - val_loss: 0.2160 - val_accuracy: 0.6909\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.8940 - val_loss: 0.2151 - val_accuracy: 0.6909\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.8756 - val_loss: 0.2113 - val_accuracy: 0.6909\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9217 - val_loss: 0.2125 - val_accuracy: 0.6909\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.8848 - val_loss: 0.2127 - val_accuracy: 0.6727\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.8848 - val_loss: 0.2148 - val_accuracy: 0.6909\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.8756 - val_loss: 0.2114 - val_accuracy: 0.7091\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9078 - val_loss: 0.2157 - val_accuracy: 0.6909\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.8940 - val_loss: 0.2183 - val_accuracy: 0.6909\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.8848 - val_loss: 0.2233 - val_accuracy: 0.6727\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9171 - val_loss: 0.2248 - val_accuracy: 0.7091\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9171 - val_loss: 0.2233 - val_accuracy: 0.7091\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9217 - val_loss: 0.2232 - val_accuracy: 0.7091\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9078 - val_loss: 0.2154 - val_accuracy: 0.6727\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.9309 - val_loss: 0.2146 - val_accuracy: 0.7091\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.8940 - val_loss: 0.2168 - val_accuracy: 0.6909\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9078 - val_loss: 0.2162 - val_accuracy: 0.6909\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.8986 - val_loss: 0.2228 - val_accuracy: 0.6909\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.8848 - val_loss: 0.2224 - val_accuracy: 0.6909\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9078 - val_loss: 0.2239 - val_accuracy: 0.7091\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.8848 - val_loss: 0.2238 - val_accuracy: 0.7091\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9032 - val_loss: 0.2142 - val_accuracy: 0.6727\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9217 - val_loss: 0.2110 - val_accuracy: 0.7091\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.8894 - val_loss: 0.2110 - val_accuracy: 0.6909\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9032 - val_loss: 0.2114 - val_accuracy: 0.7091\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9217 - val_loss: 0.2259 - val_accuracy: 0.6909\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9309 - val_loss: 0.2286 - val_accuracy: 0.6909\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9355 - val_loss: 0.2268 - val_accuracy: 0.6909\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9171 - val_loss: 0.2264 - val_accuracy: 0.7091\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9355 - val_loss: 0.2369 - val_accuracy: 0.6909\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0806 - accuracy: 0.8894 - val_loss: 0.2323 - val_accuracy: 0.6909\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9217 - val_loss: 0.2164 - val_accuracy: 0.7091\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9355 - val_loss: 0.2176 - val_accuracy: 0.7091\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9401 - val_loss: 0.2192 - val_accuracy: 0.7091\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9447 - val_loss: 0.2229 - val_accuracy: 0.7091\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9078 - val_loss: 0.2206 - val_accuracy: 0.7091\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9217 - val_loss: 0.2168 - val_accuracy: 0.6909\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9263 - val_loss: 0.2222 - val_accuracy: 0.6909\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0659 - accuracy: 0.9263 - val_loss: 0.2267 - val_accuracy: 0.7091\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9309 - val_loss: 0.2288 - val_accuracy: 0.6909\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9032 - val_loss: 0.2327 - val_accuracy: 0.6909\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9078 - val_loss: 0.2235 - val_accuracy: 0.6909\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9309 - val_loss: 0.2198 - val_accuracy: 0.6909\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.8986 - val_loss: 0.2250 - val_accuracy: 0.6909\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.8848 - val_loss: 0.2180 - val_accuracy: 0.6909\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.8940 - val_loss: 0.2198 - val_accuracy: 0.6909\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9124 - val_loss: 0.2201 - val_accuracy: 0.6909\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9263 - val_loss: 0.2214 - val_accuracy: 0.6909\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.9263 - val_loss: 0.2250 - val_accuracy: 0.6909\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9124 - val_loss: 0.2259 - val_accuracy: 0.6909\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9401 - val_loss: 0.2287 - val_accuracy: 0.6909\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9263 - val_loss: 0.2349 - val_accuracy: 0.6727\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9309 - val_loss: 0.2317 - val_accuracy: 0.6909\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9309 - val_loss: 0.2338 - val_accuracy: 0.6909\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9263 - val_loss: 0.2319 - val_accuracy: 0.6727\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9124 - val_loss: 0.2296 - val_accuracy: 0.6909\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0563 - accuracy: 0.9493 - val_loss: 0.2322 - val_accuracy: 0.6727\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9401 - val_loss: 0.2279 - val_accuracy: 0.6727\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9309 - val_loss: 0.2274 - val_accuracy: 0.6727\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0504 - accuracy: 0.9585 - val_loss: 0.2301 - val_accuracy: 0.6727\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9171 - val_loss: 0.2330 - val_accuracy: 0.6909\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9585 - val_loss: 0.2392 - val_accuracy: 0.6727\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9401 - val_loss: 0.2356 - val_accuracy: 0.6909\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9171 - val_loss: 0.2332 - val_accuracy: 0.6727\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9124 - val_loss: 0.2381 - val_accuracy: 0.6727\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9447 - val_loss: 0.2384 - val_accuracy: 0.6727\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9355 - val_loss: 0.2357 - val_accuracy: 0.6727\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9355 - val_loss: 0.2367 - val_accuracy: 0.6727\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9355 - val_loss: 0.2362 - val_accuracy: 0.6909\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9493 - val_loss: 0.2375 - val_accuracy: 0.6727\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9263 - val_loss: 0.2334 - val_accuracy: 0.6909\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9263 - val_loss: 0.2360 - val_accuracy: 0.6727\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9263 - val_loss: 0.2368 - val_accuracy: 0.6727\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9217 - val_loss: 0.2353 - val_accuracy: 0.6909\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9309 - val_loss: 0.2325 - val_accuracy: 0.6909\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9309 - val_loss: 0.2324 - val_accuracy: 0.6909\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9309 - val_loss: 0.2299 - val_accuracy: 0.6909\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9355 - val_loss: 0.2305 - val_accuracy: 0.6909\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9447 - val_loss: 0.2305 - val_accuracy: 0.6909\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9401 - val_loss: 0.2334 - val_accuracy: 0.6909\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9217 - val_loss: 0.2347 - val_accuracy: 0.6909\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9355 - val_loss: 0.2424 - val_accuracy: 0.6727\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9401 - val_loss: 0.2368 - val_accuracy: 0.6727\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9493 - val_loss: 0.2419 - val_accuracy: 0.6727\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9493 - val_loss: 0.2508 - val_accuracy: 0.6727\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9355 - val_loss: 0.2530 - val_accuracy: 0.6727\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9355 - val_loss: 0.2462 - val_accuracy: 0.6727\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9124 - val_loss: 0.2453 - val_accuracy: 0.6727\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9263 - val_loss: 0.2460 - val_accuracy: 0.6727\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9447 - val_loss: 0.2386 - val_accuracy: 0.6909\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9447 - val_loss: 0.2310 - val_accuracy: 0.7091\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9078 - val_loss: 0.2269 - val_accuracy: 0.7091\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9355 - val_loss: 0.2327 - val_accuracy: 0.6909\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9263 - val_loss: 0.2387 - val_accuracy: 0.6909\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9493 - val_loss: 0.2443 - val_accuracy: 0.6909\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9585 - val_loss: 0.2441 - val_accuracy: 0.6909\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9217 - val_loss: 0.2407 - val_accuracy: 0.6909\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9447 - val_loss: 0.2388 - val_accuracy: 0.6909\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9493 - val_loss: 0.2348 - val_accuracy: 0.6909\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9447 - val_loss: 0.2318 - val_accuracy: 0.6909\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9355 - val_loss: 0.2344 - val_accuracy: 0.6909\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9585 - val_loss: 0.2398 - val_accuracy: 0.6909\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9631 - val_loss: 0.2438 - val_accuracy: 0.6909\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9078 - val_loss: 0.2439 - val_accuracy: 0.7091\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9217 - val_loss: 0.2451 - val_accuracy: 0.6909\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9539 - val_loss: 0.2449 - val_accuracy: 0.7091\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9355 - val_loss: 0.2439 - val_accuracy: 0.6909\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9770 - val_loss: 0.2391 - val_accuracy: 0.7091\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9539 - val_loss: 0.2394 - val_accuracy: 0.7091\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9355 - val_loss: 0.2368 - val_accuracy: 0.6909\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9355 - val_loss: 0.2355 - val_accuracy: 0.7091\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9265\n",
            "accuracy: [0.06837719678878784, 0.9264705777168274]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 30)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,751\n",
            "Trainable params: 1,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 27ms/step - loss: 1.3958 - accuracy: 0.5346 - val_loss: 0.8591 - val_accuracy: 0.5455\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7195 - accuracy: 0.5392 - val_loss: 0.4430 - val_accuracy: 0.5455\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.5806 - val_loss: 0.2841 - val_accuracy: 0.6545\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2874 - accuracy: 0.6359 - val_loss: 0.2457 - val_accuracy: 0.6364\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.6682 - val_loss: 0.2390 - val_accuracy: 0.6727\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2128 - accuracy: 0.7373 - val_loss: 0.2277 - val_accuracy: 0.6727\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2000 - accuracy: 0.7604 - val_loss: 0.2130 - val_accuracy: 0.6909\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1880 - accuracy: 0.7512 - val_loss: 0.2008 - val_accuracy: 0.7455\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2032 - accuracy: 0.7235 - val_loss: 0.1906 - val_accuracy: 0.7636\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1955 - accuracy: 0.7419 - val_loss: 0.1845 - val_accuracy: 0.7818\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.7788 - val_loss: 0.1802 - val_accuracy: 0.8000\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.7327 - val_loss: 0.1773 - val_accuracy: 0.8000\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1732 - accuracy: 0.7604 - val_loss: 0.1791 - val_accuracy: 0.7636\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.8111 - val_loss: 0.1783 - val_accuracy: 0.7455\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1633 - accuracy: 0.7604 - val_loss: 0.1796 - val_accuracy: 0.7636\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.7650 - val_loss: 0.1820 - val_accuracy: 0.7455\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1518 - accuracy: 0.7880 - val_loss: 0.1823 - val_accuracy: 0.7636\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.7972 - val_loss: 0.1808 - val_accuracy: 0.7455\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.7834 - val_loss: 0.1769 - val_accuracy: 0.7455\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 0.7972 - val_loss: 0.1769 - val_accuracy: 0.7818\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.8065 - val_loss: 0.1755 - val_accuracy: 0.7636\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.8571 - val_loss: 0.1772 - val_accuracy: 0.7636\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.8571 - val_loss: 0.1736 - val_accuracy: 0.7273\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.8479 - val_loss: 0.1732 - val_accuracy: 0.7273\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.8341 - val_loss: 0.1738 - val_accuracy: 0.7273\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.8433 - val_loss: 0.1774 - val_accuracy: 0.7273\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1367 - accuracy: 0.8341 - val_loss: 0.1818 - val_accuracy: 0.7091\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.8249 - val_loss: 0.1799 - val_accuracy: 0.7091\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.8618 - val_loss: 0.1783 - val_accuracy: 0.7091\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1261 - accuracy: 0.8433 - val_loss: 0.1793 - val_accuracy: 0.7091\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1218 - accuracy: 0.8479 - val_loss: 0.1805 - val_accuracy: 0.6909\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1215 - accuracy: 0.8525 - val_loss: 0.1802 - val_accuracy: 0.6909\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1300 - accuracy: 0.8479 - val_loss: 0.1854 - val_accuracy: 0.6909\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.8341 - val_loss: 0.1906 - val_accuracy: 0.7091\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.8525 - val_loss: 0.1880 - val_accuracy: 0.6909\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1258 - accuracy: 0.8433 - val_loss: 0.1847 - val_accuracy: 0.6727\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1351 - accuracy: 0.8433 - val_loss: 0.1808 - val_accuracy: 0.6727\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.8387 - val_loss: 0.1823 - val_accuracy: 0.6909\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8802 - val_loss: 0.1836 - val_accuracy: 0.6909\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.8433 - val_loss: 0.1829 - val_accuracy: 0.6727\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1283 - accuracy: 0.8433 - val_loss: 0.1902 - val_accuracy: 0.6727\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.8571 - val_loss: 0.1902 - val_accuracy: 0.6909\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.8618 - val_loss: 0.1918 - val_accuracy: 0.6909\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.8525 - val_loss: 0.1965 - val_accuracy: 0.6909\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.8479 - val_loss: 0.1908 - val_accuracy: 0.6727\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.8710 - val_loss: 0.1868 - val_accuracy: 0.6727\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.8571 - val_loss: 0.1900 - val_accuracy: 0.6727\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.8387 - val_loss: 0.1933 - val_accuracy: 0.6727\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.8618 - val_loss: 0.1922 - val_accuracy: 0.6727\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1040 - accuracy: 0.8802 - val_loss: 0.1926 - val_accuracy: 0.6727\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.8525 - val_loss: 0.1875 - val_accuracy: 0.6909\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.8571 - val_loss: 0.1873 - val_accuracy: 0.6909\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.8433 - val_loss: 0.1851 - val_accuracy: 0.7091\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.8433 - val_loss: 0.1905 - val_accuracy: 0.6727\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.8525 - val_loss: 0.1985 - val_accuracy: 0.6727\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1068 - accuracy: 0.8710 - val_loss: 0.1982 - val_accuracy: 0.6727\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.8525 - val_loss: 0.2010 - val_accuracy: 0.6727\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.8756 - val_loss: 0.2093 - val_accuracy: 0.6727\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1032 - accuracy: 0.8802 - val_loss: 0.2088 - val_accuracy: 0.6909\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9124 - val_loss: 0.2137 - val_accuracy: 0.6909\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.8525 - val_loss: 0.2215 - val_accuracy: 0.6727\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9032 - val_loss: 0.2175 - val_accuracy: 0.6727\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.8710 - val_loss: 0.2175 - val_accuracy: 0.6727\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.8618 - val_loss: 0.2097 - val_accuracy: 0.6727\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.8710 - val_loss: 0.2071 - val_accuracy: 0.6909\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.8433 - val_loss: 0.2062 - val_accuracy: 0.6727\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.8756 - val_loss: 0.2060 - val_accuracy: 0.6909\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.8802 - val_loss: 0.1996 - val_accuracy: 0.7091\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.8664 - val_loss: 0.2017 - val_accuracy: 0.7091\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.8710 - val_loss: 0.2102 - val_accuracy: 0.6909\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.8894 - val_loss: 0.2064 - val_accuracy: 0.6909\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.8894 - val_loss: 0.2074 - val_accuracy: 0.6727\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.8986 - val_loss: 0.2150 - val_accuracy: 0.6727\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.8664 - val_loss: 0.2122 - val_accuracy: 0.6727\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.8986 - val_loss: 0.1998 - val_accuracy: 0.6727\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.8940 - val_loss: 0.1975 - val_accuracy: 0.6727\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 0.8940 - val_loss: 0.2050 - val_accuracy: 0.6727\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.8894 - val_loss: 0.2127 - val_accuracy: 0.6727\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0904 - accuracy: 0.8894 - val_loss: 0.2179 - val_accuracy: 0.6727\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9124 - val_loss: 0.2093 - val_accuracy: 0.6909\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.8940 - val_loss: 0.2046 - val_accuracy: 0.6909\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.8756 - val_loss: 0.2136 - val_accuracy: 0.6727\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.8940 - val_loss: 0.2182 - val_accuracy: 0.6727\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.8571 - val_loss: 0.2214 - val_accuracy: 0.6364\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.8940 - val_loss: 0.2310 - val_accuracy: 0.6727\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9171 - val_loss: 0.2318 - val_accuracy: 0.6545\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 0.8940 - val_loss: 0.2273 - val_accuracy: 0.6545\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.8802 - val_loss: 0.2279 - val_accuracy: 0.6545\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9124 - val_loss: 0.2257 - val_accuracy: 0.6545\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.8802 - val_loss: 0.2333 - val_accuracy: 0.6364\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9078 - val_loss: 0.2337 - val_accuracy: 0.6364\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.8986 - val_loss: 0.2197 - val_accuracy: 0.6545\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9032 - val_loss: 0.2184 - val_accuracy: 0.6545\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.8802 - val_loss: 0.2331 - val_accuracy: 0.6364\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.8986 - val_loss: 0.2342 - val_accuracy: 0.6364\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9032 - val_loss: 0.2312 - val_accuracy: 0.6727\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9171 - val_loss: 0.2285 - val_accuracy: 0.6727\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.8894 - val_loss: 0.2351 - val_accuracy: 0.6727\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.8894 - val_loss: 0.2362 - val_accuracy: 0.6545\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9032 - val_loss: 0.2395 - val_accuracy: 0.6545\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9078 - val_loss: 0.2269 - val_accuracy: 0.6545\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9124 - val_loss: 0.2293 - val_accuracy: 0.6545\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9078 - val_loss: 0.2372 - val_accuracy: 0.6545\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.8986 - val_loss: 0.2324 - val_accuracy: 0.6545\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.8894 - val_loss: 0.2259 - val_accuracy: 0.6545\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9032 - val_loss: 0.2278 - val_accuracy: 0.6545\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.8940 - val_loss: 0.2301 - val_accuracy: 0.6545\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9217 - val_loss: 0.2421 - val_accuracy: 0.6364\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9032 - val_loss: 0.2341 - val_accuracy: 0.6364\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.8802 - val_loss: 0.2231 - val_accuracy: 0.6545\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9263 - val_loss: 0.2228 - val_accuracy: 0.6364\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9263 - val_loss: 0.2222 - val_accuracy: 0.6545\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0777 - accuracy: 0.9124 - val_loss: 0.2312 - val_accuracy: 0.6545\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9124 - val_loss: 0.2353 - val_accuracy: 0.6545\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.8894 - val_loss: 0.2384 - val_accuracy: 0.6545\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.8986 - val_loss: 0.2349 - val_accuracy: 0.6545\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9032 - val_loss: 0.2335 - val_accuracy: 0.6545\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9078 - val_loss: 0.2427 - val_accuracy: 0.6545\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9124 - val_loss: 0.2348 - val_accuracy: 0.6545\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9124 - val_loss: 0.2386 - val_accuracy: 0.6545\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9171 - val_loss: 0.2299 - val_accuracy: 0.6545\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9124 - val_loss: 0.2279 - val_accuracy: 0.6545\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9217 - val_loss: 0.2348 - val_accuracy: 0.6545\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9032 - val_loss: 0.2355 - val_accuracy: 0.6545\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9124 - val_loss: 0.2378 - val_accuracy: 0.6545\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.8894 - val_loss: 0.2363 - val_accuracy: 0.6545\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9217 - val_loss: 0.2419 - val_accuracy: 0.6545\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9124 - val_loss: 0.2532 - val_accuracy: 0.6545\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9217 - val_loss: 0.2457 - val_accuracy: 0.6364\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.8940 - val_loss: 0.2503 - val_accuracy: 0.6545\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9217 - val_loss: 0.2604 - val_accuracy: 0.6545\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.8940 - val_loss: 0.2584 - val_accuracy: 0.6545\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9263 - val_loss: 0.2538 - val_accuracy: 0.6545\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0653 - accuracy: 0.9355 - val_loss: 0.2567 - val_accuracy: 0.6545\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9401 - val_loss: 0.2588 - val_accuracy: 0.6545\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9401 - val_loss: 0.2496 - val_accuracy: 0.6545\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.8894 - val_loss: 0.2446 - val_accuracy: 0.6182\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9217 - val_loss: 0.2572 - val_accuracy: 0.6545\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9309 - val_loss: 0.2639 - val_accuracy: 0.6545\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9493 - val_loss: 0.2559 - val_accuracy: 0.6364\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.9263 - val_loss: 0.2541 - val_accuracy: 0.6364\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9401 - val_loss: 0.2432 - val_accuracy: 0.6364\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.8986 - val_loss: 0.2425 - val_accuracy: 0.6545\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9171 - val_loss: 0.2437 - val_accuracy: 0.6545\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.8940 - val_loss: 0.2367 - val_accuracy: 0.6182\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9217 - val_loss: 0.2450 - val_accuracy: 0.6182\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9263 - val_loss: 0.2573 - val_accuracy: 0.6545\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9032 - val_loss: 0.2628 - val_accuracy: 0.6545\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0815 - accuracy: 0.8894 - val_loss: 0.2613 - val_accuracy: 0.6545\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9263 - val_loss: 0.2518 - val_accuracy: 0.6727\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9032 - val_loss: 0.2362 - val_accuracy: 0.6727\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9032 - val_loss: 0.2480 - val_accuracy: 0.6727\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.9124 - val_loss: 0.2541 - val_accuracy: 0.6727\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9124 - val_loss: 0.2484 - val_accuracy: 0.6727\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9355 - val_loss: 0.2442 - val_accuracy: 0.6364\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9263 - val_loss: 0.2459 - val_accuracy: 0.6727\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9078 - val_loss: 0.2399 - val_accuracy: 0.6727\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9309 - val_loss: 0.2348 - val_accuracy: 0.6727\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.9217 - val_loss: 0.2521 - val_accuracy: 0.6727\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0616 - accuracy: 0.9355 - val_loss: 0.2568 - val_accuracy: 0.6727\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9585 - val_loss: 0.2528 - val_accuracy: 0.6727\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9355 - val_loss: 0.2609 - val_accuracy: 0.6727\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9309 - val_loss: 0.2487 - val_accuracy: 0.6909\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9355 - val_loss: 0.2471 - val_accuracy: 0.6909\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0595 - accuracy: 0.9217 - val_loss: 0.2516 - val_accuracy: 0.6727\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9539 - val_loss: 0.2497 - val_accuracy: 0.6909\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9447 - val_loss: 0.2448 - val_accuracy: 0.6909\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9355 - val_loss: 0.2410 - val_accuracy: 0.6727\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9401 - val_loss: 0.2513 - val_accuracy: 0.6909\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9355 - val_loss: 0.2513 - val_accuracy: 0.6727\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9217 - val_loss: 0.2496 - val_accuracy: 0.6727\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9355 - val_loss: 0.2442 - val_accuracy: 0.6545\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0631 - accuracy: 0.9263 - val_loss: 0.2463 - val_accuracy: 0.6364\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9263 - val_loss: 0.2480 - val_accuracy: 0.6545\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0758 - accuracy: 0.9355 - val_loss: 0.2527 - val_accuracy: 0.6909\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0582 - accuracy: 0.9309 - val_loss: 0.2520 - val_accuracy: 0.6727\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9309 - val_loss: 0.2527 - val_accuracy: 0.6727\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0514 - accuracy: 0.9401 - val_loss: 0.2503 - val_accuracy: 0.6545\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9401 - val_loss: 0.2571 - val_accuracy: 0.6545\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0625 - accuracy: 0.9217 - val_loss: 0.2611 - val_accuracy: 0.6545\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9309 - val_loss: 0.2497 - val_accuracy: 0.6545\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9263 - val_loss: 0.2428 - val_accuracy: 0.7091\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9309 - val_loss: 0.2508 - val_accuracy: 0.6909\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9401 - val_loss: 0.2538 - val_accuracy: 0.6909\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9355 - val_loss: 0.2479 - val_accuracy: 0.6727\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9447 - val_loss: 0.2420 - val_accuracy: 0.6545\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9124 - val_loss: 0.2562 - val_accuracy: 0.6727\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9401 - val_loss: 0.2490 - val_accuracy: 0.6727\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9401 - val_loss: 0.2491 - val_accuracy: 0.6727\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9539 - val_loss: 0.2519 - val_accuracy: 0.6727\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9309 - val_loss: 0.2449 - val_accuracy: 0.6727\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9355 - val_loss: 0.2462 - val_accuracy: 0.6727\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9263 - val_loss: 0.2413 - val_accuracy: 0.7091\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9539 - val_loss: 0.2454 - val_accuracy: 0.6909\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9493 - val_loss: 0.2421 - val_accuracy: 0.6909\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9401 - val_loss: 0.2595 - val_accuracy: 0.7091\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9355 - val_loss: 0.2603 - val_accuracy: 0.7091\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9539 - val_loss: 0.2582 - val_accuracy: 0.6727\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9217 - val_loss: 0.2665 - val_accuracy: 0.6545\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9447 - val_loss: 0.2615 - val_accuracy: 0.6727\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9118\n",
            "accuracy: [0.07723977416753769, 0.9117646813392639]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_test, y_test, epochs= 100, batch_size=30)\n",
        "loss = model.evaluate(x_test,y_test)\n",
        "print('accuracy:',loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82gBB-SXEvNP",
        "outputId": "cc25d640-eded-4c97-e5eb-ccf0bf8cd5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.8387\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1829 - accuracy: 0.8065\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.8065\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1351 - accuracy: 0.9032\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1475 - accuracy: 0.8387\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9355\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9032\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.8387\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9032\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.8065\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.8710\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9032\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1383 - accuracy: 0.8387\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9677\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9677\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9677\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9032\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9032\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9032\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9355\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9355\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9032\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.9355\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.9032\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9032\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.9032\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9677\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9677\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0813 - accuracy: 0.9032\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0472 - accuracy: 0.9677\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0646 - accuracy: 0.9355\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9355\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9677\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0686 - accuracy: 0.9032\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0446 - accuracy: 0.9355\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9355\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9355\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9355\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9355\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9355\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9032\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.9032\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.8710\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9355\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9677\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9677\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9355\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9677\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9677\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9032\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9032\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9677\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9355\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9677\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9677\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9677\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9677\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.8387\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9677\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9677\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9032\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9355\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9355\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0687 - accuracy: 0.9032\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9355\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9677\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9677\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9677\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9677\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9677\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9355\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9355\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.8710\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9677\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9677\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9677\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9355\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9677\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9677\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9677\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9032\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0661 - accuracy: 0.9355\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9677\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "accuracy: [0.011193206533789635, 1.0]\n"
          ]
        }
      ]
    }
  ]
}